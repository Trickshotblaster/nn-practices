{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyN0NezMlRDdqm/uddw8lfvG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Trickshotblaster/nn-practices/blob/main/TransformerV3TPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mF1Wi04gwqoL"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
        "raw_text = requests.get(url).text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_amount = 0.9\n",
        "train_text, val_text = raw_text[:int(len(raw_text) * train_amount)], raw_text[int(len(raw_text) * train_amount):]\n",
        "train_text[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ARWYIXl9xFNT",
        "outputId": "a3fa0a21-ad41-4f94-ac31-fda3cd0caf18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = set(raw_text)\n",
        "vocab.add(\"<|UNK|>\")\n",
        "vocab = sorted(vocab)\n",
        "\n",
        "stoi = {char:i for i, char in enumerate(vocab)}\n",
        "itos = {i:char for i, char in enumerate(stoi)}\n",
        "itos[stoi['<|UNK|>']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YY3cBAtMxaNW",
        "outputId": "3f224774-ffd0-414c-c99a-8b4aeac28f52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|UNK|>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Tokenizer:\n",
        "  def __init__(self, stoi, itos):\n",
        "    self.stoi = stoi\n",
        "    self.itos = itos\n",
        "  def __len__(self):\n",
        "    return len(self.stoi) - 1\n",
        "  def encode(self, text):\n",
        "    return [stoi.get(char, stoi['<|UNK|>']) for char in text]\n",
        "  def decode(self, tokens):\n",
        "    return \"\".join([itos.get(token, '<|UNK|>') for token in tokens])\n",
        "tokenizer = Tokenizer(stoi, itos)\n",
        "tokenizer.decode(tokenizer.encode(\"hello world ^}|%\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2tqyzMtdyA44",
        "outputId": "601e7696-1f33-4707-cde8-b72de88ce3f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hello world <|UNK|><|UNK|><|UNK|><|UNK|>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "GKc4Oey01Gif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_len = 16\n",
        "emb_dim = 32\n",
        "import math\n",
        "def create_positional_encoding_matrix(max_seq_len, emb_dim):\n",
        "  mask = torch.zeros((max_seq_len, emb_dim))\n",
        "  for pos in range(max_seq_len):\n",
        "    for i in range(0, emb_dim, 2):\n",
        "      mask[pos, i] = math.sin(pos/(10000 ** ((2*i)/emb_dim)))\n",
        "      mask[pos, i+1] = math.cos(pos/(10000 ** ((2*(i+1))/emb_dim)))\n",
        "  return mask\n",
        "positional_encoding_matrix = create_positional_encoding_matrix(max_seq_len, emb_dim)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(positional_encoding_matrix.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "rhLazuVi0Xs3",
        "outputId": "cff701b4-cb61-4991-89c0-542b0e4c2f77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7e820c592620>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MaskedMultiHeadAttention(nn.Module):\n",
        "  def __init__(self, n_heads, emb_dim):\n",
        "    super().__init__()\n",
        "    assert emb_dim % n_heads == 0, \"Embedding dimension must be divisible by head number\"\n",
        "    self.n_heads = n_heads\n",
        "    self.emb_dim = emb_dim\n",
        "    self.head_size = emb_dim // n_heads\n",
        "    self.wq = nn.Linear(emb_dim, emb_dim)\n",
        "    self.wk = nn.Linear(emb_dim, emb_dim)\n",
        "    self.wv = nn.Linear(emb_dim, emb_dim)\n",
        "\n",
        "    self.wo = nn.Linear(emb_dim, emb_dim)\n",
        "  def forward(self, x):\n",
        "    batch_size, seq_len, emb_dim = x.size()\n",
        "    Q = self.wq(x).view(batch_size, seq_len, self.n_heads, self.head_size).transpose(1, 2)\n",
        "    K = self.wk(x).view(batch_size, seq_len, self.n_heads, self.head_size).transpose(1, 2)\n",
        "    V = self.wv(x).view(batch_size, seq_len, self.n_heads, self.head_size).transpose(1, 2)\n",
        "\n",
        "    scaled_dot_product = (torch.matmul(Q, K.transpose(2, 3)))/(self.head_size**0.5)\n",
        "\n",
        "    attn_mask = torch.triu(\n",
        "        torch.ones(seq_len, seq_len),\n",
        "        diagonal=1\n",
        "    ).to(device)\n",
        "    attn_mask.masked_fill_(attn_mask==1, float('-inf'))\n",
        "\n",
        "    scaled_dot_product += attn_mask\n",
        "\n",
        "    attn_scores = torch.matmul(F.softmax(scaled_dot_product, dim=-1), V)\n",
        "    attn_scores = attn_scores.view(batch_size, -1, self.n_heads * self.head_size)\n",
        "\n",
        "    out = self.wo(attn_scores)\n",
        "\n",
        "    return out # (batch_size, seq_len, emb_dim)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-Mcx23B5lFO",
        "outputId": "162236d6-a444-44f7-847d-a2e81fccd62d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 2.3461e-01,  4.9978e-01, -5.8001e-02,  9.7791e-02,  3.8873e-02,\n",
              "          -2.7843e-01, -1.8957e-01,  5.1536e-02, -1.8104e-01,  7.1944e-03,\n",
              "           7.9413e-03,  2.8555e-01,  7.8404e-02, -9.6415e-02,  3.7422e-02,\n",
              "          -1.3509e-01,  2.6016e-01, -2.1465e-02,  9.6084e-02,  5.3424e-02,\n",
              "           6.5205e-02,  3.1046e-01,  2.9622e-01, -2.0063e-01,  2.3900e-01,\n",
              "           1.2731e-01, -8.4547e-02,  6.0434e-03, -9.0917e-02,  6.0460e-02,\n",
              "          -6.0112e-02,  1.4407e-01],\n",
              "         [ 2.1582e-01,  5.1136e-01, -8.1883e-02,  9.1253e-02,  8.4480e-02,\n",
              "          -2.7785e-01, -1.8405e-01,  7.4366e-02, -2.1105e-01, -1.9305e-02,\n",
              "          -2.7408e-02,  2.6630e-01,  9.8041e-02, -6.4037e-02,  1.1066e-01,\n",
              "          -9.0400e-02,  2.6965e-01, -5.9027e-02,  7.0760e-02,  7.8228e-02,\n",
              "           9.3511e-02,  2.9761e-01,  3.1977e-01, -1.7494e-01,  2.2251e-01,\n",
              "           1.3551e-01, -1.0322e-01,  7.8441e-03, -1.5735e-01,  4.0059e-02,\n",
              "          -8.3660e-02,  1.4393e-01],\n",
              "         [ 1.7759e-01,  3.3233e-01, -2.0709e-02, -1.3818e-02, -3.2019e-03,\n",
              "          -8.4343e-02, -2.0849e-01,  6.6373e-02, -6.0905e-02,  6.8518e-02,\n",
              "          -9.2200e-03,  1.2114e-01, -3.1651e-02,  6.4972e-02,  2.5627e-02,\n",
              "          -1.0411e-01,  1.0372e-01, -6.9879e-02,  9.9016e-02, -1.1088e-01,\n",
              "           8.4034e-02,  3.0443e-01,  2.1094e-01, -1.8501e-01,  1.5587e-01,\n",
              "           7.1734e-03, -1.8632e-02,  1.1519e-01, -5.6441e-02, -1.1198e-02,\n",
              "          -5.2171e-02,  3.3151e-02],\n",
              "         [ 1.7998e-01,  3.1495e-01, -2.4446e-02,  1.7826e-03, -2.9679e-03,\n",
              "          -1.4537e-01, -2.6141e-01,  5.8931e-02, -1.2630e-01,  6.3045e-02,\n",
              "          -4.6174e-03,  1.2562e-01,  2.4300e-03,  2.0505e-02,  1.5785e-02,\n",
              "          -1.0280e-01,  1.1336e-01, -1.1446e-01,  1.3576e-01, -8.6883e-02,\n",
              "           9.2773e-02,  3.1459e-01,  1.8064e-01, -1.4950e-01,  2.1082e-01,\n",
              "           8.9351e-02, -6.9188e-02,  6.5810e-02, -2.9996e-03, -6.2885e-02,\n",
              "          -2.0837e-02,  3.8154e-02],\n",
              "         [ 1.4556e-01,  2.8949e-01, -1.0422e-01, -2.7986e-02,  1.9403e-01,\n",
              "          -9.2431e-02,  1.3205e-02, -2.2657e-03, -2.1136e-02,  1.9196e-02,\n",
              "           2.0118e-01,  1.9592e-01, -1.1302e-01,  1.1588e-01,  1.2963e-01,\n",
              "          -3.4900e-02,  3.8679e-02, -1.0297e-01,  1.9163e-02,  2.0951e-02,\n",
              "           1.0789e-01,  6.8228e-02,  2.5679e-02,  5.5916e-02,  8.7315e-02,\n",
              "           2.3709e-01, -1.4998e-01,  2.0638e-01,  2.1149e-01,  8.1111e-02,\n",
              "          -1.6900e-01, -1.5084e-01],\n",
              "         [ 1.2261e-01,  3.0024e-01, -9.5063e-02, -1.0278e-02,  2.4498e-01,\n",
              "          -1.4825e-01,  9.1876e-03,  5.1221e-03,  1.2431e-03,  3.6357e-03,\n",
              "           1.7316e-01,  1.1469e-01, -1.2378e-01,  1.1692e-01,  1.4694e-01,\n",
              "          -9.1713e-03,  4.0289e-03, -1.4844e-01, -5.6081e-05, -3.7463e-02,\n",
              "           1.0588e-01,  6.4670e-02,  1.2623e-02,  4.5293e-02,  7.1403e-02,\n",
              "           2.3618e-01, -1.4659e-01,  1.9909e-01,  2.4743e-01,  4.8117e-02,\n",
              "          -1.6539e-01, -1.3133e-01],\n",
              "         [ 1.8505e-01,  2.8011e-01, -1.1432e-01, -5.0722e-02,  1.4964e-01,\n",
              "          -1.4980e-01, -5.8325e-02, -5.2616e-03, -2.9616e-02,  4.6787e-02,\n",
              "           1.8306e-01,  1.9541e-01, -9.7825e-02,  9.7348e-02,  1.2889e-01,\n",
              "           6.9349e-03,  4.6832e-02, -1.0251e-01,  4.8791e-02, -3.1588e-02,\n",
              "           6.5480e-02,  2.0691e-02, -1.6712e-02,  9.2174e-02,  1.1869e-01,\n",
              "           3.5034e-01, -1.1405e-01,  1.4661e-01,  2.9835e-01, -2.7191e-02,\n",
              "          -9.2488e-02, -1.6482e-01],\n",
              "         [ 2.0018e-01,  2.4909e-01, -1.4233e-01, -1.8369e-02,  1.4953e-01,\n",
              "          -1.2597e-01, -5.6302e-02,  2.7034e-02, -5.9274e-02,  5.0963e-02,\n",
              "           1.7865e-01,  1.8034e-01, -9.7626e-02,  1.7375e-01,  8.2778e-02,\n",
              "          -1.1366e-02,  4.4656e-02, -9.4531e-02,  1.8557e-02, -3.7570e-02,\n",
              "           4.8126e-02,  8.1767e-04, -1.2848e-02,  1.0075e-01,  8.1990e-02,\n",
              "           2.9911e-01, -7.2784e-02,  1.5587e-01,  2.5676e-01, -1.6922e-02,\n",
              "          -7.3086e-02, -1.6674e-01],\n",
              "         [ 3.2791e-01,  1.5262e-01, -1.3291e-01,  1.3201e-01, -4.6810e-02,\n",
              "          -5.3355e-01, -3.0800e-01,  6.1588e-02, -3.1711e-01,  1.8735e-01,\n",
              "           1.1992e-01,  2.6062e-01, -4.9441e-02, -6.6591e-02,  5.7979e-02,\n",
              "          -4.0122e-01,  4.0156e-01, -1.1160e-01,  1.2166e-01,  1.3896e-01,\n",
              "           5.9406e-02,  2.1976e-01,  2.1359e-01, -4.8982e-03,  3.5138e-01,\n",
              "           2.9576e-01,  1.1757e-02, -2.1757e-01, -2.7097e-02, -1.7031e-01,\n",
              "           3.0922e-02,  1.2277e-01],\n",
              "         [ 2.6053e-01,  1.3205e-01, -1.4151e-01,  2.1177e-01, -9.5847e-02,\n",
              "          -5.0611e-01, -3.1402e-01,  1.4870e-01, -3.0256e-01,  1.8859e-01,\n",
              "           8.9292e-02,  2.1043e-01, -6.0821e-02, -3.4670e-02,  3.1323e-02,\n",
              "          -3.7595e-01,  4.0064e-01, -1.7650e-01,  1.2603e-01,  6.9621e-02,\n",
              "           6.9534e-02,  2.4143e-01,  1.8689e-01,  3.5125e-02,  3.9904e-01,\n",
              "           3.1430e-01, -3.5916e-02, -2.1558e-01, -7.8515e-02, -1.7226e-01,\n",
              "           8.0155e-02,  6.4607e-02],\n",
              "         [ 2.7250e-01, -4.0736e-02, -1.2010e-01, -3.2071e-02, -2.0739e-01,\n",
              "          -2.0899e-01, -3.0516e-01,  3.6903e-02, -1.6153e-01,  2.6866e-01,\n",
              "           7.6183e-02,  1.1218e-01, -1.6840e-01,  1.1245e-01, -4.2244e-02,\n",
              "          -3.6107e-01,  2.0743e-01, -2.3731e-01,  1.8054e-01, -4.1673e-02,\n",
              "           4.4002e-02,  1.9109e-01,  4.8670e-02,  2.1288e-02,  2.8807e-01,\n",
              "           1.8921e-01,  7.5410e-02, -1.5993e-02,  8.5808e-02, -2.7210e-01,\n",
              "           8.2258e-02, -8.9944e-02],\n",
              "         [ 1.8801e-01, -4.4918e-02, -1.0309e-01, -5.7041e-03, -1.2680e-01,\n",
              "          -2.2418e-01, -3.5951e-01,  7.4117e-02, -2.1131e-01,  2.3103e-01,\n",
              "           7.7892e-02,  5.4681e-02, -1.6676e-01,  7.5692e-02, -5.2507e-02,\n",
              "          -3.3464e-01,  1.2772e-01, -2.8925e-01,  1.2145e-01, -4.0889e-02,\n",
              "           1.0040e-01,  1.8955e-01,  3.3983e-02,  5.6779e-02,  2.8737e-01,\n",
              "           1.3818e-01, -2.7102e-04,  2.2604e-02,  1.4574e-01, -2.2882e-01,\n",
              "           8.2577e-02, -9.3778e-02],\n",
              "         [ 1.4860e-01,  2.0427e-01,  5.6713e-02, -1.3734e-01, -7.8252e-02,\n",
              "           1.5155e-02, -3.1487e-01,  7.9657e-03, -3.5958e-02,  1.3712e-01,\n",
              "           8.2394e-03, -3.5062e-02, -1.5016e-01,  1.2823e-01, -4.5759e-02,\n",
              "          -1.5095e-01, -7.7238e-02, -2.0487e-01,  2.0918e-01, -1.8719e-01,\n",
              "           1.0266e-01,  3.2941e-01,  7.7412e-02, -1.1506e-01,  1.7898e-01,\n",
              "          -5.8622e-02, -2.0641e-02,  2.1980e-01,  7.1608e-02, -8.8470e-02,\n",
              "          -6.3842e-02, -7.9918e-02],\n",
              "         [ 1.5821e-01,  2.4859e-01,  5.9243e-02, -1.4749e-01, -3.4788e-02,\n",
              "           1.8780e-02, -3.4296e-01,  1.8868e-03, -1.3915e-02,  1.4851e-01,\n",
              "          -3.2995e-02,  3.4434e-03, -1.6796e-01,  1.2444e-01,  1.1495e-02,\n",
              "          -1.1767e-01, -7.5694e-02, -1.9349e-01,  2.3335e-01, -2.3401e-01,\n",
              "           1.2819e-01,  3.1192e-01,  7.0125e-02, -1.0878e-01,  1.7812e-01,\n",
              "          -7.1548e-02, -3.2445e-02,  2.3531e-01,  7.2217e-02, -6.8890e-02,\n",
              "          -8.2356e-02, -7.3168e-02],\n",
              "         [ 7.8377e-02,  2.6252e-01, -1.7837e-01,  2.8984e-02,  1.7594e-01,\n",
              "           7.3663e-02,  1.7648e-01,  1.1681e-01,  4.0683e-02, -3.3387e-03,\n",
              "           1.4424e-01,  2.4075e-01,  6.7201e-03,  1.4593e-01,  1.0861e-01,\n",
              "           4.2015e-02,  2.6301e-02, -1.6330e-02, -9.7214e-02, -4.2574e-02,\n",
              "           7.8385e-02,  8.6680e-02,  3.6296e-02, -3.5511e-02, -8.6790e-02,\n",
              "           1.9987e-01, -1.5951e-01,  2.8271e-01,  2.9770e-01,  4.2357e-02,\n",
              "          -1.0573e-01, -2.0467e-01],\n",
              "         [ 4.5050e-02,  3.1284e-01, -1.2882e-01,  4.5520e-03,  1.5501e-01,\n",
              "          -5.3664e-04,  1.4059e-01,  1.2253e-01,  7.9071e-02, -2.1206e-02,\n",
              "           1.8293e-01,  2.7326e-01,  7.7831e-03,  6.7968e-02,  4.5469e-02,\n",
              "           8.5749e-02,  2.2767e-02, -4.8569e-02, -1.9132e-01, -2.1568e-02,\n",
              "           2.7100e-02, -8.3463e-03,  3.6828e-02, -1.1233e-01, -5.4201e-02,\n",
              "           2.1837e-01, -6.2638e-02,  2.1963e-01,  3.4652e-01,  9.7399e-02,\n",
              "          -3.7667e-02, -2.0260e-01]]], grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self, in_size, hidden_size, out_size):\n",
        "    super().__init__()\n",
        "    self.l1 = nn.Linear(in_size, hidden_size)\n",
        "    self.l2 = nn.Linear(hidden_size, out_size)\n",
        "    self.act = nn.GELU()\n",
        "  def forward(self, ins):\n",
        "    hidden = self.act(self.l1(ins))\n",
        "    return self.act(self.l2(hidden))"
      ],
      "metadata": {
        "id": "hW5QG80_K_2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self, n_heads, emb_dim):\n",
        "    super().__init__()\n",
        "    self.layernorm = nn.LayerNorm(emb_dim)\n",
        "    self.n_heads = n_heads\n",
        "    self.emb_dim = emb_dim\n",
        "    self.MHA = MaskedMultiHeadAttention(n_heads, emb_dim)\n",
        "    self.MLP = MLP(emb_dim, emb_dim * 4, emb_dim)\n",
        "  def forward(self, ins):\n",
        "    residual = ins.clone()\n",
        "    attention_result = self.MHA(ins)\n",
        "    attention_result += residual\n",
        "    normalized_attention_result = self.layernorm(attention_result)\n",
        "    residual2 = normalized_attention_result.clone()\n",
        "    MLP_out = self.MLP(normalized_attention_result)\n",
        "    MLP_out += residual2\n",
        "    out = self.layernorm(MLP_out)\n",
        "    return out\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnKYzMWbMPcR",
        "outputId": "137ac157-6577-4ca0-98ad-086ed098b10c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.3480,  1.4857, -0.6613, -0.1879, -0.4310,  0.6775, -1.0171,\n",
              "           0.5601,  0.4434,  0.0724, -1.6670,  1.0363,  0.6657, -1.2474,\n",
              "          -0.5774, -1.4791,  1.1693,  0.5102, -0.5863,  1.3048,  0.1757,\n",
              "           1.5577,  0.5967,  0.1966,  0.0292, -0.6843, -0.1641, -1.3997,\n",
              "          -1.7510,  2.3677, -0.8653, -0.4783],\n",
              "         [-0.6586,  0.1690,  0.2151,  0.1472, -0.9148,  2.0712, -0.3504,\n",
              "           1.4613, -0.1667,  1.0654, -1.0099, -0.4491,  0.9314, -0.4997,\n",
              "          -0.8162, -0.9806,  1.6746, -1.0379, -0.1951, -0.6157, -2.2204,\n",
              "           0.1802,  1.0561,  1.6190, -0.0973,  0.4730,  1.3115, -0.7508,\n",
              "          -1.7981, -0.2263,  0.3952,  0.0177],\n",
              "         [ 0.6081,  0.2984, -1.5913, -1.2482,  1.1193,  1.2269,  0.7327,\n",
              "          -1.2182,  0.1108,  0.1959, -0.8538,  0.7994, -0.5710,  1.5305,\n",
              "           1.2279, -0.7629, -2.1865, -1.0441, -0.4247,  1.3450,  0.3511,\n",
              "           0.2187, -0.0837, -0.5016,  0.4879,  0.3769, -1.0243,  1.3328,\n",
              "          -0.5009, -0.2090, -1.3993,  1.6572],\n",
              "         [ 1.1109,  0.5121,  0.5989, -0.5716, -1.3728,  0.7605,  0.4401,\n",
              "           0.1397,  0.8804, -1.0298, -1.3511, -1.5041, -0.3532, -0.1142,\n",
              "           0.6400, -1.0290, -0.4638,  1.1088, -1.1661,  2.3122,  1.1510,\n",
              "           1.1851,  0.9293,  1.4974, -0.2714,  0.7843, -0.7156, -0.9699,\n",
              "          -0.4461, -0.1387, -1.2192, -1.3340],\n",
              "         [-1.5670, -0.5890,  0.7798, -1.3466,  0.8514, -2.0798,  0.2471,\n",
              "           0.7471,  0.5907,  0.7506,  0.2660,  1.4698,  0.1085, -1.0094,\n",
              "           0.8784,  1.3683, -0.9919, -1.1442, -0.4344, -0.0613,  1.1175,\n",
              "          -0.6134, -1.7945,  1.1792, -0.3599, -0.4034,  0.1379, -0.9495,\n",
              "           0.9132,  1.7358,  0.5947, -0.3918],\n",
              "         [ 1.4687, -0.9249, -0.7864, -0.0116,  2.4814, -1.0644, -1.0780,\n",
              "           0.5813, -0.8835, -1.7103,  0.1331,  0.7758, -0.8226,  1.9313,\n",
              "           0.4331, -0.2757, -0.6851, -0.0237, -0.4333,  0.6025,  0.2015,\n",
              "           0.7454,  0.4376, -0.3399,  1.1201, -1.3955,  0.2051,  0.5601,\n",
              "          -1.5990,  1.3828, -0.7429, -0.2828],\n",
              "         [ 0.5286, -1.3806, -0.3472, -1.1019, -0.1674, -0.0644, -1.1247,\n",
              "          -1.1879, -0.7866, -0.5017,  0.7563, -0.1302,  0.6307, -0.7221,\n",
              "           0.4979,  0.3509,  2.4602, -1.1247,  1.8239,  0.4195,  1.0444,\n",
              "           0.5405,  1.0842,  1.0897,  0.4834,  0.8650, -1.3744, -1.1162,\n",
              "          -1.4988, -0.2142, -0.8688,  1.1367],\n",
              "         [-1.0517, -0.5023, -2.0399,  0.9321,  0.0403, -0.0826,  1.2944,\n",
              "          -1.3311,  0.1917,  0.3581, -1.4859,  0.2778, -0.2031,  0.4913,\n",
              "           0.0431,  2.2333, -0.1358,  0.1246, -0.9625, -0.7424,  1.7372,\n",
              "          -0.4833, -0.8872, -0.2435, -0.3830,  0.9740,  0.5183,  0.1183,\n",
              "          -0.4813,  2.0391, -1.4024,  1.0441],\n",
              "         [ 0.1905, -0.4930, -0.5651, -1.5822, -0.6272,  1.3292,  0.0425,\n",
              "           1.0484, -2.0049, -0.4326,  0.4727,  0.7514, -0.2484,  1.0716,\n",
              "          -1.1646,  0.3966,  2.4235, -0.7454, -0.2764, -1.4245,  0.7974,\n",
              "          -1.6833, -0.6979, -0.1676,  0.8328,  1.1754,  0.0430,  1.3483,\n",
              "          -0.5883,  0.8654,  0.4069, -0.4941],\n",
              "         [-1.1675, -0.2666,  0.2115, -1.6472,  1.1309, -0.9165,  0.8191,\n",
              "          -1.4963,  1.0118,  0.1439,  2.2429, -0.0369,  0.1311,  0.8192,\n",
              "          -2.2056,  1.2260,  1.2991,  0.5941, -0.0453,  0.3003, -0.3586,\n",
              "          -0.3763,  0.2949, -1.5075,  0.3824,  1.2647, -0.6864,  0.5085,\n",
              "          -1.2487, -0.8659,  0.2277,  0.2175],\n",
              "         [ 0.5534,  1.3031,  0.5344, -2.1070,  0.2375,  1.4383,  0.5674,\n",
              "          -0.4573,  1.2422, -0.2260,  0.1540, -0.5027, -0.3411,  0.7468,\n",
              "          -1.3151,  0.7284, -0.4108, -1.8690, -0.0757,  1.2438, -0.4216,\n",
              "          -0.9384,  0.0180,  0.1439,  0.1748, -0.1515, -1.6331, -1.4117,\n",
              "           1.7359, -1.0304,  0.4940,  1.5757],\n",
              "         [-1.0831, -0.5105, -0.0825,  0.8334, -0.3874,  0.0931,  1.8668,\n",
              "          -1.2127, -0.9863, -0.6176, -1.3080, -2.3961,  0.3619,  0.7368,\n",
              "          -1.2803, -0.4657,  0.6392,  1.3697,  0.4421,  1.6818,  0.0671,\n",
              "          -0.9650,  1.1953,  0.8323,  1.1318,  1.1651,  0.3133, -0.4389,\n",
              "          -1.0233,  0.7314,  0.0283, -0.7320],\n",
              "         [-0.4396, -0.1259,  0.4016, -0.6157, -0.1228,  0.1867,  1.6868,\n",
              "           0.3675,  1.5423, -0.4196, -0.3671,  0.6154,  2.8194,  0.1747,\n",
              "          -0.7376, -1.4532, -0.9090, -0.9944, -0.4258,  1.0698, -0.8413,\n",
              "           0.6809,  0.5683, -1.6660, -0.6136,  1.0843,  0.0067, -2.2892,\n",
              "           0.1551,  0.4368,  0.3032, -0.0788],\n",
              "         [ 0.3190,  0.2852,  0.9074, -0.9379,  0.2618,  2.0845,  0.3044,\n",
              "           1.2353, -0.0163, -0.3491,  0.0143, -1.1973,  1.7627, -0.8587,\n",
              "          -0.2916,  2.0958, -0.8184, -1.1330,  0.7181, -0.8069,  0.0266,\n",
              "           0.4844, -0.6219, -1.9744, -0.4549,  1.7444, -0.3826, -1.1881,\n",
              "           0.4167, -1.0580,  0.1015, -0.6728],\n",
              "         [ 0.3190, -0.1480, -1.6601, -0.9458, -0.1576,  0.9328,  1.1234,\n",
              "          -0.8395,  2.0112, -0.2114, -0.2774, -0.9767,  1.6383,  0.6144,\n",
              "          -0.6391, -0.3429,  0.5021,  0.2551, -1.1154, -0.8509,  1.1676,\n",
              "          -0.9214, -0.3706, -0.7391, -1.0336,  1.5968, -0.0473,  0.8704,\n",
              "          -0.9759, -0.9620, -0.0989,  2.2824],\n",
              "         [-1.1844,  1.4955,  0.4484, -1.4703,  0.3659, -0.8871,  0.5535,\n",
              "           1.3902, -0.3725, -0.1380, -0.8450,  0.8141, -1.8731, -0.3296,\n",
              "          -0.4981,  0.1169, -0.8777,  0.4106, -0.3522, -1.6491,  0.4419,\n",
              "           1.1875,  1.4261,  1.1405, -1.9520, -0.3967,  1.2328, -0.8849,\n",
              "           1.1539,  0.9699,  0.2932,  0.2697]]],\n",
              "       grad_fn=<NativeLayerNormBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT(nn.Module):\n",
        "  def __init__(self, n_heads, emb_dim, max_seq_len, n_blocks, tokenizer):\n",
        "    super().__init__()\n",
        "    self.n_heads = n_heads\n",
        "    self.emb_dim = emb_dim\n",
        "    self.max_seq_len = max_seq_len\n",
        "    self.n_blocks = n_blocks\n",
        "    self.tokenizer = tokenizer\n",
        "    self.layernorm = nn.LayerNorm(emb_dim)\n",
        "    self.emb = nn.Embedding(len(tokenizer) + 1, emb_dim)\n",
        "    self.pos_encoding_matrix = create_positional_encoding_matrix(max_seq_len, emb_dim).to(device)\n",
        "    self.decoder_stack = nn.ModuleList([\n",
        "        TransformerBlock(n_heads, emb_dim)\n",
        "        for _ in range(n_blocks)\n",
        "    ])\n",
        "\n",
        "    self.logits_layer = nn.Linear(emb_dim, len(tokenizer)+1)\n",
        "  def forward(self, ins):\n",
        "    embedding = self.emb(ins)\n",
        "    pos_encoding_indices = torch.arange(ins.shape[1]).to(device) # seq_len\n",
        "\n",
        "    x = embedding\n",
        "    x += self.pos_encoding_matrix[pos_encoding_indices]\n",
        "\n",
        "    for decoder in self.decoder_stack:\n",
        "      x = decoder(x)\n",
        "\n",
        "    x = self.layernorm(x)\n",
        "    logits = self.logits_layer(x)\n",
        "    return logits\n",
        "  @torch.no_grad()\n",
        "  def generate(self, text, length=10):\n",
        "    out = \"\"\n",
        "    for x in range(length):\n",
        "      encodings = torch.tensor(self.tokenizer.encode(text + out)).to(device)\n",
        "      seq_len = len(encodings)\n",
        "      if seq_len > self.max_seq_len:\n",
        "        encodings = encodings[len(encodings) - self.max_seq_len:]\n",
        "      tokens = encodings.view(1, -1)\n",
        "      logits = self.forward(tokens)[0, -1, :] # logits for last char\n",
        "      probs = F.softmax(logits, dim=-1)\n",
        "      selection_index = torch.multinomial(probs, num_samples=1)\n",
        "      out += self.tokenizer.decode([selection_index.item()])\n",
        "    return out"
      ],
      "metadata": {
        "id": "GEt7OmRIPcGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch_xla.core.xla_model as xm"
      ],
      "metadata": {
        "id": "3L1WtwykQtit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_len = 32\n",
        "emb_dim = 32\n",
        "n_heads = 8\n",
        "n_blocks = 10\n",
        "\n",
        "lr = 0.001\n",
        "batch_size = 64\n",
        "max_epochs = 3\n",
        "\n",
        "log_period = 1000\n",
        "\n",
        "device = xm.xla_device()#torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "myGPT = GPT(n_heads, emb_dim, max_seq_len, n_blocks, tokenizer)\n",
        "myGPT = myGPT.to(device)\n",
        "print(\"Total params:\", sum(p.numel() for p in myGPT.parameters()))\n",
        "if torch.cuda.is_available():\n",
        "  myGPT = torch.compile(myGPT, backend='aot_torchxla_trace_once')\n",
        "optim = torch.optim.AdamW(myGPT.parameters(), lr=lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgwFWjqEiTUr",
        "outputId": "0aea7aaa-6541-4adb-b712-5e57731d3301"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total params: 130754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_dataset(max_seq_len, tokens):\n",
        "  context_x = tokens[:max_seq_len]\n",
        "  context_y = tokens[1:max_seq_len+1]\n",
        "  x_examples = [context_x]\n",
        "  y_examples = [context_y]\n",
        "  for token, next in zip(tokens[max_seq_len:], tokens[max_seq_len+1:]):\n",
        "    context_x = context_x[1:]\n",
        "    context_x.append(token)\n",
        "    context_y = context_y[1:]\n",
        "    context_y.append(next)\n",
        "    x_examples.append(context_x)\n",
        "    y_examples.append(context_y)\n",
        "  return torch.tensor(x_examples).long().to(device), torch.tensor(y_examples).to(device)\n",
        "tokenized_train_data = tokenizer.encode(train_text)\n",
        "Xtr, Ytr = generate_dataset(max_seq_len, tokenized_train_data)\n",
        "tokenized_test_data = tokenizer.encode(val_text)\n",
        "Xte, Yte = generate_dataset(max_seq_len, tokenized_test_data)\n",
        "tokenizer.decode(Xtr[0].cpu().numpy()), tokenizer.decode(Ytr[0].cpu().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atTGrKNsfhZn",
        "outputId": "9913b3e7-72a4-4cb6-f2ac-dda2ce6cd16c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('First Citizen:\\nBefore we proceed', 'irst Citizen:\\nBefore we proceed ')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_len = len(Xtr) - 1\n",
        "max_steps = (train_len // batch_size) * max_epochs\n",
        "for step in range(max_steps): # max_steps\n",
        "  batch_indices = torch.randint(0, train_len, (batch_size,)).to(device)\n",
        "  x_batch = Xtr[batch_indices]\n",
        "  y_batch = Ytr[batch_indices].view(-1)\n",
        "\n",
        "  logits = myGPT(x_batch)\n",
        "  logits = logits.view(-1, logits.size(-1))\n",
        "  loss = F.cross_entropy(logits, y_batch)\n",
        "  optim.zero_grad()\n",
        "  loss.backward()\n",
        "  optim.step()\n",
        "\n",
        "  if step % log_period == 0:\n",
        "    print(\"Step\", str(step) + \", loss:\", loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5esfI5aiapD",
        "outputId": "ada8d1b3-a237-4e12-843d-81c1caef78fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0, loss: 4.462635040283203\n",
            "Step 1000, loss: 0.09450148791074753\n",
            "Step 2000, loss: 0.0831683948636055\n",
            "Step 3000, loss: 0.06723348051309586\n",
            "Step 4000, loss: 0.0618027001619339\n",
            "Step 5000, loss: 0.06486377865076065\n",
            "Step 6000, loss: 0.05567563325166702\n",
            "Step 7000, loss: 0.06839106231927872\n",
            "Step 8000, loss: 0.05807604268193245\n",
            "Step 9000, loss: 0.06374622881412506\n",
            "Step 10000, loss: 0.057793326675891876\n",
            "Step 11000, loss: 0.04828006401658058\n",
            "Step 12000, loss: 0.0573645643889904\n",
            "Step 13000, loss: 0.05887402594089508\n",
            "Step 14000, loss: 0.061360716819763184\n",
            "Step 15000, loss: 0.059712402522563934\n",
            "Step 16000, loss: 0.0519883818924427\n",
            "Step 17000, loss: 0.06995172053575516\n",
            "Step 18000, loss: 0.048565030097961426\n",
            "Step 19000, loss: 0.0469779372215271\n",
            "Step 20000, loss: 0.050306953489780426\n",
            "Step 21000, loss: 0.0665665790438652\n",
            "Step 22000, loss: 0.05625740811228752\n",
            "Step 23000, loss: 0.051283299922943115\n",
            "Step 24000, loss: 0.047473613172769547\n",
            "Step 25000, loss: 0.04904669523239136\n",
            "Step 26000, loss: 0.051967423409223557\n",
            "Step 27000, loss: 0.0596674382686615\n",
            "Step 28000, loss: 0.05501728877425194\n",
            "Step 29000, loss: 0.04528206214308739\n",
            "Step 30000, loss: 0.059297967702150345\n",
            "Step 31000, loss: 0.04581320658326149\n",
            "Step 32000, loss: 0.05693436786532402\n",
            "Step 33000, loss: 0.055399537086486816\n",
            "Step 34000, loss: 0.055826276540756226\n",
            "Step 35000, loss: 0.04368095472455025\n",
            "Step 36000, loss: 0.05473697930574417\n",
            "Step 37000, loss: 0.0553906112909317\n",
            "Step 38000, loss: 0.056141458451747894\n",
            "Step 39000, loss: 0.03649275004863739\n",
            "Step 40000, loss: 0.05718796327710152\n",
            "Step 41000, loss: 0.05521871894598007\n",
            "Step 42000, loss: 0.06299769878387451\n",
            "Step 43000, loss: 0.06003239005804062\n",
            "Step 44000, loss: 0.059624310582876205\n",
            "Step 45000, loss: 0.05756537243723869\n",
            "Step 46000, loss: 0.03733716160058975\n",
            "Step 47000, loss: 0.04740050807595253\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(myGPT.generate(\"\\n\", length=500))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eEOVX6D20m3",
        "outputId": "21163f25-c0c5-4f42-b0e6-aada6f7b0614"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "UKDDLinLLDLO\n",
            "ERDTAce:ARELELY:\n",
            "Sissy, sir!\n",
            "\n",
            "MENENIUS:\n",
            "You wife, met, before to a- wing as non!\n",
            "\n",
            "CALIOPY:\n",
            "What I cravented cose\n",
            "Is them's roveness.\n",
            "\n",
            "GLOUCESTER:\n",
            "Voot, I carrant your from a sains,\n",
            "Killowing secreat.\n",
            "\n",
            "CAPHARD:\n",
            "Here comes be in the gove and the ministed\n",
            "Well not ressed, herl, my lease:\n",
            " here, as bless, thou mewly to thou have thhe broopt. Murder,\n",
            "Sadmon that for such A gerre any\n",
            "To king sent buckingue!\n",
            "Hall consportune for.\n",
            "\n",
            "Second Seport.\n",
            "But a do impossing my long place;\n",
            "Fein\n"
          ]
        }
      ]
    }
  ]
}