{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXduHXuxpNYQsGO70NyVNE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Trickshotblaster/nn-practices/blob/main/actual_words.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vlOyA0vd1yYH"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tokenizers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BcD5gPE2Kep",
        "outputId": "68c4721a-c7d8-4ca0-a31b-22e144508ae3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tokenizers\n",
            "  Downloading tokenizers-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface_hub<0.17,>=0.16.4 (from tokenizers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers) (3.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers) (23.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<0.17,>=0.16.4->tokenizers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<0.17,>=0.16.4->tokenizers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<0.17,>=0.16.4->tokenizers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<0.17,>=0.16.4->tokenizers) (2023.7.22)\n",
            "Installing collected packages: huggingface_hub, tokenizers\n",
            "Successfully installed huggingface_hub-0.16.4 tokenizers-0.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))"
      ],
      "metadata": {
        "id": "NzClVptB12Jp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers.trainers import BpeTrainer\n",
        "trainer = BpeTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])"
      ],
      "metadata": {
        "id": "A3Rxokcr2IjQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "tokenizer.pre_tokenizer = Whitespace()"
      ],
      "metadata": {
        "id": "cvh_tXAz2Uzh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-103-raw-v1.zip\n",
        "!unzip wikitext-103-raw-v1.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ij7TOdzN2biA",
        "outputId": "97d48c37-bf88-4f25-fe92-ea460902903a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-28 22:12:33--  https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-103-raw-v1.zip\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.215.32, 52.216.213.208, 54.231.134.240, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.215.32|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 191984949 (183M) [application/zip]\n",
            "Saving to: ‘wikitext-103-raw-v1.zip’\n",
            "\n",
            "wikitext-103-raw-v1 100%[===================>] 183.09M  63.9MB/s    in 2.9s    \n",
            "\n",
            "2023-09-28 22:12:37 (63.9 MB/s) - ‘wikitext-103-raw-v1.zip’ saved [191984949/191984949]\n",
            "\n",
            "Archive:  wikitext-103-raw-v1.zip\n",
            "   creating: wikitext-103-raw/\n",
            "  inflating: wikitext-103-raw/wiki.test.raw  \n",
            "  inflating: wikitext-103-raw/wiki.valid.raw  \n",
            "  inflating: wikitext-103-raw/wiki.train.raw  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files = [f\"wikitext-103-raw/wiki.{split}.raw\" for split in [\"test\", \"train\", \"valid\"]]\n",
        "tokenizer.train(files, trainer)"
      ],
      "metadata": {
        "id": "ZBn84zFL2hwB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.save(\"tokenizer-wiki.json\")"
      ],
      "metadata": {
        "id": "8QI79bKN2mO5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer.from_file(\"tokenizer-wiki.json\")"
      ],
      "metadata": {
        "id": "DwGQU7F92vtI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = tokenizer.encode(\"Hello, y'all! How are you 😁 ?\")\n",
        "out_tensor = torch.tensor(output.ids)"
      ],
      "metadata": {
        "id": "Evntl6tB2yD4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(out_tensor.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4q1Ct9_X3kGY",
        "outputId": "2b13db69-d079-4097-cc35-23f34fb87fd5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hello , y ' all ! How are you ?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}