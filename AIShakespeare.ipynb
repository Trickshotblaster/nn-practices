{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnSWbR2qpOLrHzyd9waYzZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Trickshotblaster/nn-practices/blob/main/AIShakespeare.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "ERzFbn1Q2CX4"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
        "url = 'https://raw.githubusercontent.com/google/maxtext/main/MaxText/train.py'\n",
        "text = requests.get(url).text"
      ],
      "metadata": {
        "id": "Lw8FBuTdzMAs"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(set(text))\n",
        "vocab_size = len(vocab) + 1\n",
        "block_size = 5\n",
        "stoi = {' ': 0}\n",
        "itos = {0: ' '}\n",
        "stoi.update({char:i+1 for i, char in enumerate(vocab)})\n",
        "itos.update({i+1:char for i, char in enumerate(vocab)})\n",
        "def build_dataset(text, block_size):\n",
        "  xs = []\n",
        "  ys = []\n",
        "  block = [0] * block_size\n",
        "  for char, next in zip(text, text[1:]):\n",
        "    block = block[1:] + [stoi[char]]\n",
        "    xs.append(block)\n",
        "    ys.append(stoi[next])\n",
        "  return xs, ys\n",
        "def make_splits(text, block_size, split_amounts):\n",
        "  train_text = text[0: int(len(text) * split_amounts[0])]\n",
        "  dev_text = text[int(len(text) * split_amounts[0]): int(len(text) * split_amounts[0]) + int(len(text) * split_amounts[1])]\n",
        "  test_text = text[int(len(text) * split_amounts[0]) + int(len(text) * split_amounts[1]):]\n",
        "  Xtr, Ytr = build_dataset(train_text, block_size)\n",
        "  Xdev, Ydev = build_dataset(dev_text, block_size)\n",
        "  Xte, Yte = build_dataset(test_text, block_size)\n",
        "  return torch.tensor(Xtr), torch.tensor(Ytr), torch.tensor(Xdev), torch.tensor(Ydev), torch.tensor(Xte), torch.tensor(Yte)\n",
        "\n",
        "Xtr, Ytr, Xdev, Ydev, Xte, Yte = make_splits(text, block_size, [0.8, 0.1])\n",
        "print(Xtr[0], Ytr[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc7YmXQozjcp",
        "outputId": "ed42b635-2322-4ab3-c735-e77bb4a20995"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 0, 4]) tensor(4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb_dim = 10\n",
        "hidden_size = 200\n",
        "C = torch.randn(vocab_size, emb_dim)\n",
        "w1 = torch.randn(block_size * emb_dim, hidden_size) / ((block_size * emb_dim)**0.5)\n",
        "b1 = torch.randn(hidden_size)\n",
        "w2 = torch.randn(hidden_size, vocab_size) / (hidden_size ** 0.5)\n",
        "b2 = torch.randn(vocab_size)\n",
        "\n",
        "params = [C, w1, b1, w2, b2]\n",
        "for p in params:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "id": "d41x4PpI3EuQ"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "ins = C[Xtr[20]].view(-1)\n",
        "l1 = (ins @ w1 + b1).tanh()\n",
        "out = F.softmax(l1 @ w2 + b2, dim=0)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQC63eGZ4oRC",
        "outputId": "84a43173-4ef2-415a-8b47-b452dac6cb7d"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0006, 0.0035, 0.0112, 0.0054, 0.0017, 0.0040, 0.0025, 0.0045, 0.0129,\n",
            "        0.0005, 0.0147, 0.0051, 0.0096, 0.0072, 0.0056, 0.0008, 0.0056, 0.0049,\n",
            "        0.0009, 0.0016, 0.0070, 0.0452, 0.0157, 0.0094, 0.0026, 0.0352, 0.0026,\n",
            "        0.0063, 0.0041, 0.0021, 0.0063, 0.0163, 0.0097, 0.0082, 0.0065, 0.0122,\n",
            "        0.0048, 0.1084, 0.0133, 0.0017, 0.0108, 0.0121, 0.0074, 0.0082, 0.0005,\n",
            "        0.0122, 0.0150, 0.0099, 0.0118, 0.0728, 0.0826, 0.0115, 0.0021, 0.0061,\n",
            "        0.0079, 0.0026, 0.0301, 0.0034, 0.0098, 0.0015, 0.0042, 0.0036, 0.0014,\n",
            "        0.0037, 0.0423, 0.0043, 0.0246, 0.0018, 0.0028, 0.0503, 0.0033, 0.0020,\n",
            "        0.0018, 0.0513, 0.0114, 0.0016, 0.0015, 0.0005, 0.0070, 0.0031, 0.0175,\n",
            "        0.0108, 0.0104], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 20\n",
        "batch_size = 16\n",
        "train_len = len(Xtr) - 1\n",
        "max_steps = (train_len // batch_size) * num_epochs\n",
        "lr = 1"
      ],
      "metadata": {
        "id": "FIDG2Obr20yL"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for step in range(max_steps):\n",
        "  batch_indices = torch.randint(0, train_len, (batch_size,))\n",
        "  x_batch = Xtr[batch_indices]\n",
        "  y_batch = Ytr[batch_indices]\n",
        "  emb = C[x_batch].view(batch_size, -1)\n",
        "  l1 = (emb @ w1 + b1).tanh()\n",
        "\n",
        "  out = F.softmax(l1 @ w2 + b2, dim=1)\n",
        "\n",
        "  loss = -out[torch.arange(batch_size), y_batch].log().mean() + sum(w.mean() **2 for w in params) * 0.1\n",
        "\n",
        "\n",
        "  for p in params:\n",
        "    p.grad = None\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  for p in params:\n",
        "    p.data -= p.grad * lr\n",
        "\n",
        "  if step % 10000 == 0:\n",
        "    print(\"Step\", str(step) + \", loss:\", loss.item())\n",
        "  elif step % 100 == 0:\n",
        "    lr *= 0.9"
      ],
      "metadata": {
        "id": "_sAd07Zv43l0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aac13d5-db00-4f94-cbd6-d1eefeb52c96"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0, loss: 5.416100025177002\n",
            "Step 10000, loss: 1.1861125230789185\n",
            "Step 20000, loss: 1.8722206354141235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate():\n",
        "  out_str = \"\"\n",
        "  context = [0] * block_size\n",
        "  for x in range(500):\n",
        "    c = torch.tensor(context)\n",
        "    emb = C[c].view(-1)\n",
        "    l1 = l1 = (emb @ w1 + b1).tanh()\n",
        "    out = F.softmax(l1 @ w2 + b2, dim=0)\n",
        "    index = torch.multinomial(out, num_samples=1)\n",
        "    context = context[1:] + [index.item()]\n",
        "    out_str += itos[index.item()]\n",
        "  return out_str\n",
        "print(generate())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2Yy_5DyWwAC",
        "outputId": "2208f9c8-ca16-4b94-d594-59e702b326b0"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tesJ)\n",
            "    ),\n",
            "      checkiointragloste( \"config, getut_te soine_dite_config.enites metrics\n",
            "\n",
            "\n",
            " motrics(istart_trannog d\")\n",
            "  if config.rum:\n",
            "     checkiny\n",
            ", config.ssmax_utils.l2acratpert[\": training_rate_sche4ral.step fram.chath\n",
            "  if tabp sioring loss)\n",
            "  putation\"], writer.sGing/metrics to -.artswite_shard_tutions\n",
            "    re):\n",
            "  \"\"\"\n",
            "\n",
            "\n",
            "def re Ooms)\n",
            "  Oem Nore( as jon ind eval_loss_mpares al(n, medrics = functionngciog_luter leconfig, stepsmes confil\n",
            "          mesh, s: en che, coneconfig, parse__rate_pof\n"
          ]
        }
      ]
    }
  ]
}