{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3Q6AcEJ3DVexnUdosfCCJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Trickshotblaster/nn-practices/blob/main/MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-fiyn4RDHgUG"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/karpathy/makemore/master/names.txt'\n",
        "\n",
        "response = requests.get(url)\n",
        "\n",
        "with open('names.txt', 'wb') as f:\n",
        "  f.write(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "kLD2Wy_sHoVP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = open('names.txt', 'r').read().splitlines()\n",
        "words[:8]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88ggro_GHxUL",
        "outputId": "385e5b47-d8b5-494b-f996-77d37769172e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sp-ZkQeHH8dM",
        "outputId": "16ecbe55-f191-4a74-b554-9952a02dd558"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32033"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# stoi and itos\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {char:i+1 for i, char in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:char for char, i in stoi.items()}\n",
        "print(itos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrRzXj6_H9_p",
        "outputId": "58b7b393-39fd-4da7-f57d-1dd50a9a0afd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make dataset\n",
        "block_size = 3 # context length\n",
        "X, Y = [], []\n",
        "for w in words[:5]:\n",
        "  print(w)\n",
        "  context = [0] * block_size # list of zeros of length block size\n",
        "  for ch in w + '.':\n",
        "    ix = stoi[ch]\n",
        "    X.append(context)\n",
        "    Y.append(ix)\n",
        "    print(''.join(itos[i] for i in context), '---->', itos[ix])\n",
        "    context = context[1:] + [ix] # crop to remove previous, append new to end\n",
        "\n",
        "X = torch.tensor(X)\n",
        "Y = torch.tensor(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNUt-PmgI50U",
        "outputId": "5232df63-a287-4757-bc62-3d714a374bf6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emma\n",
            "... ----> e\n",
            "..e ----> m\n",
            ".em ----> m\n",
            "emm ----> a\n",
            "mma ----> .\n",
            "olivia\n",
            "... ----> o\n",
            "..o ----> l\n",
            ".ol ----> i\n",
            "oli ----> v\n",
            "liv ----> i\n",
            "ivi ----> a\n",
            "via ----> .\n",
            "ava\n",
            "... ----> a\n",
            "..a ----> v\n",
            ".av ----> a\n",
            "ava ----> .\n",
            "isabella\n",
            "... ----> i\n",
            "..i ----> s\n",
            ".is ----> a\n",
            "isa ----> b\n",
            "sab ----> e\n",
            "abe ----> l\n",
            "bel ----> l\n",
            "ell ----> a\n",
            "lla ----> .\n",
            "sophia\n",
            "... ----> s\n",
            "..s ----> o\n",
            ".so ----> p\n",
            "sop ----> h\n",
            "oph ----> i\n",
            "phi ----> a\n",
            "hia ----> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, X.dtype, Y.shape, Y.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZvm2Lj-Kpq9",
        "outputId": "e0ab076d-76ec-43cf-e450-da974bfdd6b2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 3]), torch.int64, torch.Size([32]), torch.int64)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# C should be a 27 x embedding dimension matrix\n",
        "C = torch.randn((27, 2))"
      ],
      "metadata": {
        "id": "j1pTZxiJK-OT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C[stoi['a']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJm6cJxQLXNK",
        "outputId": "a9966809-a03c-454c-d9e1-381d5516628f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.6173, 0.3393])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aonehot = F.one_hot(torch.tensor(stoi['a']), num_classes=27).float()\n",
        "aonehot @ C"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_JtzD1RLji4",
        "outputId": "d189cd65-3dd6-4c75-9dd8-50429facf9ba"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.6173, 0.3393])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C[[5, 6, 7]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avdx0fogMg-h",
        "outputId": "45e7f723-46e0-466a-88b4-e9611ffce232"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.4724,  1.8303],\n",
              "        [-0.6621,  0.3525],\n",
              "        [ 0.1849, -1.7818]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C[torch.tensor([0,0,0])]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwSdfY_oM486",
        "outputId": "e27b6150-bf61-4645-9981-edc9a88acc0d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.4356, -1.1651],\n",
              "        [-0.4356, -1.1651],\n",
              "        [-0.4356, -1.1651]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for data in X[:5]:\n",
        "  enc = C[data]\n",
        "  print(enc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfYBbOH0MqeP",
        "outputId": "f62095e4-8d49-443d-bd17-d3542f93e172"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4356, -1.1651],\n",
            "        [-0.4356, -1.1651],\n",
            "        [-0.4356, -1.1651]])\n",
            "tensor([[-0.4356, -1.1651],\n",
            "        [-0.4356, -1.1651],\n",
            "        [ 0.4724,  1.8303]])\n",
            "tensor([[-0.4356, -1.1651],\n",
            "        [ 0.4724,  1.8303],\n",
            "        [ 0.9653, -0.1961]])\n",
            "tensor([[ 0.4724,  1.8303],\n",
            "        [ 0.9653, -0.1961],\n",
            "        [ 0.9653, -0.1961]])\n",
            "tensor([[ 0.9653, -0.1961],\n",
            "        [ 0.9653, -0.1961],\n",
            "        [ 0.6173,  0.3393]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb = C[X]\n",
        "emb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfGYToMPNK1q",
        "outputId": "3a38b357-0393-4d05-b8af-c6c884ddbab6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%time\n",
        "torch.cat([emb[:, 0, :], emb[:, 1, :], emb[:, 2, :]], 1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_axHK2K7PZmI",
        "outputId": "702b1114-decc-468c-89c1-82cdc165c082"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 6.68 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%time\n",
        "torch.flatten(emb, start_dim=1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKO-OeWbPzJm",
        "outputId": "ff1069cd-45a2-479c-e1c9-2d98c4a10494"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 4.53 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%time\n",
        "torch.cat(torch.unbind(emb, 1), 1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSv2BLpcQh_V",
        "outputId": "8803a08e-6e33-43e4-d77f-e070df9ef9cb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
            "Wall time: 5.96 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Idk bruh I think mine is still better"
      ],
      "metadata": {
        "id": "0irXVt_TQ87o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.arange(18)\n",
        "a, a.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJCZLwk2RIKV",
        "outputId": "0501f2d2-c161-4151-a97b-6563cf6d12c9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17]),\n",
              " torch.Size([18]))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.view(3, 6) # holy moly where has this been all my life"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXRTu3BERTJp",
        "outputId": "820666a4-a73a-4d23-c9eb-7427ad03ac5d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  1,  2,  3,  4,  5],\n",
              "        [ 6,  7,  8,  9, 10, 11],\n",
              "        [12, 13, 14, 15, 16, 17]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%time\n",
        "emb.view(32, 6).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvvIoQX8Rb9H",
        "outputId": "cacddfa2-14d8-4b57-fd35-f7a134a39aef"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
            "Wall time: 5.01 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 microseconds bruv"
      ],
      "metadata": {
        "id": "br3PNmn-RxIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C = torch.randn((27, 2))\n",
        "w1 = torch.randn(6, 100)\n",
        "b1 = torch.randn(100)\n",
        "w2 = torch.randn(100, 27)\n",
        "b2 = torch.randn(27)\n",
        "\n",
        "wi1 = emb.view(-1, 6) @ w1\n",
        "wi1b = wi1 + b1\n",
        "wi1ba = wi1b.tanh()\n",
        "wi2 = wi1ba @ w2\n",
        "logits = wi2 + b2\n",
        "counts = logits.exp()\n",
        "probs = counts / counts.sum(1, keepdim=True)\n",
        "\n",
        "parameters = [C, w1, b1, w2, b2]\n",
        "for p in parameters:\n",
        "  p.requires_grad = True\n",
        "probs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3bPMri3NnAo",
        "outputId": "d2a9abfb-2041-46be-ae6e-791878614ab0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = -probs[torch.arange(32), Y].log().mean()\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVnoYLPyK7Yi",
        "outputId": "c07ff33e-b0e6-4f66-cb8e-2c9a6f511605"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(18.0028)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb = C[X]\n",
        "wi1 = emb.view(-1, 6) @ w1\n",
        "wi1b = wi1 + b1\n",
        "wi1ba = wi1b.tanh()\n",
        "wi2 = wi1ba @ w2\n",
        "logits = wi2 + b2\n",
        "counts = logits.exp()\n",
        "probs = counts / counts.sum(1, keepdim=True)\n",
        "\n",
        "\n",
        "for p in parameters:\n",
        "  p.grad = None\n",
        "\n",
        "loss = -probs[torch.arange(len(X)), Y].log().mean()\n",
        "print(loss)\n",
        "loss.backward()\n",
        "for p in parameters:\n",
        "  p.data -= p.grad * 0.01\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hASN8gqCLzlU",
        "outputId": "c44e0757-b791-4b89-e410-b0dcc2200f98"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10.6617, grad_fn=<NegBackward0>)\n",
            "10.661726951599121\n"
          ]
        }
      ]
    }
  ]
}