{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4bNFUyAbvL+cJOBlsh8xp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Trickshotblaster/nn-practices/blob/main/GoodShakespeare.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "yY1Z4GSP4kpa"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
        "text = requests.get(url)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "_MhuV9pFk1zN"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = text.text"
      ],
      "metadata": {
        "id": "mb0kHEqg4xMS"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = text.lower()"
      ],
      "metadata": {
        "id": "eaUVI0rY42x1"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = text.split()"
      ],
      "metadata": {
        "id": "AJyD920j4-xH"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_dict = set()\n",
        "for word in vocab:\n",
        "  if random.randint(1, 10) > 7:\n",
        "    vocab_dict.update([word])"
      ],
      "metadata": {
        "id": "vj5k8Fau5A3D"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEaUNI-u5e2r",
        "outputId": "c169079c-6d5f-47e0-f5cc-4c61dadbc260"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11437"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_dict = sorted(vocab_dict)"
      ],
      "metadata": {
        "id": "7EqF9ERD6fxL"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = {\"[PAD]\": 0, \"[UNK]\": 1}\n",
        "itos = {0: \"[PAD]\", 1: \"[UNK]\"}\n",
        "stoi.update({char:i for i, char in enumerate(vocab_dict)})\n",
        "itos.update({i:char for i, char in enumerate(vocab_dict)})"
      ],
      "metadata": {
        "id": "dIV5fbje59uP"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Tokenizer:\n",
        "  def __init__(self, stoi, itos, len=10):\n",
        "    self.stoi = stoi\n",
        "    self.itos = itos\n",
        "    self.len = len\n",
        "  def encode(self, text, crop=True):\n",
        "    out = []\n",
        "    if crop:\n",
        "      for word in text.lower().split()[:self.len]:\n",
        "        if word in stoi:\n",
        "          out.append(stoi[word])\n",
        "        else:\n",
        "          out.append(1)\n",
        "      out = [0] * (self.len - len(out)) + out\n",
        "      return out\n",
        "    else:\n",
        "      for word in text.lower().split():\n",
        "        if word in stoi:\n",
        "          out.append(stoi[word])\n",
        "        else:\n",
        "          out.append(1)\n",
        "      out = [0] * (self.len - len(out)) + out\n",
        "      return out\n",
        "  def decode(self, ids):\n",
        "    out = \"\"\n",
        "    for id in ids:\n",
        "      if id in itos:\n",
        "        out += itos[id] + \" \"\n",
        "      else:\n",
        "        out += '[UNK] '\n",
        "    return out"
      ],
      "metadata": {
        "id": "YYif7lrG6uyB"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(stoi, itos)"
      ],
      "metadata": {
        "id": "9NeN4k1x8fg4"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(\"hello world\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhKIv2b98i7P",
        "outputId": "7bf29623-ff1d-40da-b4e5-0b1d658cb8dc"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 0, 0, 0, 0, 1, 11240]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "tSvA5LK788Im"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_len = 10\n",
        "emb_dim = 10\n",
        "vocab_size = len(stoi)\n",
        "n_hidden = 200\n",
        "C = torch.randn(vocab_size, emb_dim) * 0.1\n",
        "w1 = torch.randn(context_len * emb_dim, n_hidden) * 0.1\n",
        "b1 = torch.randn(n_hidden) * 0.01\n",
        "w2 = torch.randn(n_hidden, vocab_size) * 0.1\n",
        "b2 = torch.randn(vocab_size) * 0.01\n",
        "\n",
        "params = [C, w1, b1, w2, b2]\n",
        "for p in params:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "id": "ENZrsino89iC"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10000\n",
        "lr = 0.01\n",
        "batch_size = 16"
      ],
      "metadata": {
        "id": "_6_FqERW_I28"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dataset(text):\n",
        "  xs = []\n",
        "  ys = []\n",
        "  tokenized_text = tokenizer.encode(text, crop=False)\n",
        "  context = [0] * (context_len)\n",
        "  for x in tokenized_text:\n",
        "    xs.append(context)\n",
        "    ys.append(x)\n",
        "    context = context[1:] + [x]\n",
        "  xs = torch.tensor(xs)\n",
        "  ys = torch.tensor(ys)\n",
        "  return xs, ys\n",
        "Xtr, Ytr = build_dataset(text)\n",
        "train_examples = len(Xtr) - 1"
      ],
      "metadata": {
        "id": "ieiNgYuHfFuP"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "ihNO403RjcPT"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  batch_indices = torch.randint(0, train_examples, (batch_size, ))\n",
        "  xs = Xtr[batch_indices]\n",
        "  ys = Ytr[batch_indices]\n",
        "  emb = C[xs].view(-1, emb_dim * context_len)\n",
        "  l1 = (emb @ w1 + b1).tanh()\n",
        "  logits = (l1 @ w2 + b2).tanh()\n",
        "  loss = F.cross_entropy(logits, ys)\n",
        "\n",
        "  for p in params:\n",
        "    p.grad = None\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  for p in params:\n",
        "    p.data -= p.grad * lr\n",
        "\n",
        "  if epoch % 1000 == 0:\n",
        "    print(\"Epoch\", str(epoch) + \", loss:\", loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUkAfTx6i1xO",
        "outputId": "403f2f4a-3d49-4689-a6a0-bc96ba16c3bc"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, loss: 9.311010360717773\n",
            "Epoch 1000, loss: 9.0848388671875\n",
            "Epoch 2000, loss: 9.001920700073242\n",
            "Epoch 3000, loss: 8.89068603515625\n",
            "Epoch 4000, loss: 8.96533203125\n",
            "Epoch 5000, loss: 8.924089431762695\n",
            "Epoch 6000, loss: 8.835135459899902\n",
            "Epoch 7000, loss: 8.904825210571289\n",
            "Epoch 8000, loss: 8.741148948669434\n",
            "Epoch 9000, loss: 8.69002914428711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prompt(text, len=10):\n",
        "  output = text\n",
        "  for x in range(len):\n",
        "    xs = tokenizer.encode(output)\n",
        "    emb = C[xs].view(-1, emb_dim * context_len)\n",
        "    l1 = (emb @ w1 + b1).tanh()\n",
        "    logits = (l1 @ w2 + b2).tanh()\n",
        "    outs = logits.softmax(dim=1)\n",
        "    output += tokenizer.decode(torch.multinomial(outs, num_samples=1))\n",
        "  return output"
      ],
      "metadata": {
        "id": "wQyRO80BlcdG"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt(\"hello\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "w-gXmwqNmRT0",
        "outputId": "cb022f0b-a141-4daa-dc90-9e979f745304"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hello[UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    }
  ]
}