{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Trickshotblaster/nn-practices/blob/main/TrigramLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import math"
      ],
      "metadata": {
        "id": "PiuT_51Tl7Nv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3ev7uHfxkMiG"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
        "url = 'https://raw.githubusercontent.com/karpathy/makemore/master/names.txt'\n",
        "url = 'https://raw.githubusercontent.com/Trickshotblaster/nn-practices/main/TrigramLM.ipynb'\n",
        "response = requests.get(url)\n",
        "\n",
        "with open('file.txt', 'wb') as f:\n",
        "  f.write(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('file.txt', 'r') as data:\n",
        "  dataset = data.readlines()\n",
        "\n",
        "with open('file.txt', 'r') as data:\n",
        "  raw_data = data.read()\n"
      ],
      "metadata": {
        "id": "VeY-m-Udk9vA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6b0O8l00lsV5",
        "outputId": "0da269a0-9591-45b1-b8e1-2898f88735d7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\\n  \"nbfor'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = raw_data.split(\"\\n\")"
      ],
      "metadata": {
        "id": "94Huj2vsI8IW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMddGXOulfd7",
        "outputId": "c2ff8425-fd0f-496e-fe19-d17ee90bc22f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['{',\n",
              " '  \"nbformat\": 4,',\n",
              " '  \"nbformat_minor\": 0,',\n",
              " '  \"metadata\": {',\n",
              " '    \"colab\": {',\n",
              " '      \"provenance\": [],',\n",
              " '      \"include_colab_link\": true',\n",
              " '    },',\n",
              " '    \"kernelspec\": {',\n",
              " '      \"name\": \"python3\",']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = dataset[:math.floor(len(dataset) * 0.8)]\n",
        "dev_set = dataset[math.floor(len(dataset) * 0.8):math.floor(len(dataset) * 0.9)]\n",
        "test_set = dataset[math.floor(len(dataset) * 0.9):len(dataset) - 1]"
      ],
      "metadata": {
        "id": "tysnVzUhfSBI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = set(raw_data)"
      ],
      "metadata": {
        "id": "r8SisRZnmsXN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_len = len(vocab)"
      ],
      "metadata": {
        "id": "Z4j0KdGLlLZv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fq2cq6wClYmI",
        "outputId": "8180ce4a-a1bd-426e-e41e-e66109d22fab"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = {char:i for i, char in enumerate(vocab)}"
      ],
      "metadata": {
        "id": "9KA09eJhmbl2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "itos = {i:char for i, char in enumerate(vocab)}"
      ],
      "metadata": {
        "id": "RjRr7qIVm7Qx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "lRWpmX5jpbnE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as functional"
      ],
      "metadata": {
        "id": "9rCZJJKhp4LV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make dataset\n",
        "xs, ys = [], []\n",
        "for data in train_set:\n",
        "  for ch1, ch2, ch3 in zip(data, data[1:], data[2:]):\n",
        "    xs.append([stoi[ch1], stoi[ch2]])\n",
        "    ys.append(stoi[ch3])\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n",
        "num = xs.nelement()\n",
        "num"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nhNqsYvl0xm",
        "outputId": "5c229119-e613-432f-ca24-9147eb6593d8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24196"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ws = torch.randn((vocab_len*2, vocab_len))\n",
        "ws.requires_grad = True\n",
        "ws.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gEB2g5WpfRE",
        "outputId": "ecd3e844-2298-46b1-868f-a269230b6614"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([168, 84])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xenc = functional.one_hot(xs[0], num_classes=vocab_len).float().flatten()\n",
        "xenc @ ws"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2cwT-tEpvpL",
        "outputId": "b850e5e9-e894-4089-9706-9b0ecb1528e7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.0560e+00,  1.2743e-01,  1.1645e+00,  1.2119e+00,  1.1744e+00,\n",
              "         2.5078e+00,  5.8928e-01, -4.8063e-01, -2.0613e-01,  1.1768e+00,\n",
              "        -2.1398e+00,  2.7658e+00,  2.5778e+00, -1.3192e+00,  1.7091e+00,\n",
              "         3.9220e-01,  2.2703e-01,  1.6676e+00,  4.6383e-01, -4.0720e+00,\n",
              "        -7.9494e-01, -8.5573e-01, -3.4151e+00, -1.4738e+00,  5.5158e-01,\n",
              "        -2.6002e+00, -6.3340e-01, -1.0440e+00, -3.0220e-01, -2.4106e+00,\n",
              "        -1.1312e-01, -1.1008e+00, -8.1029e-02,  1.1450e+00,  1.5008e+00,\n",
              "         1.0374e+00, -5.2829e-01,  1.3812e-01, -1.8724e+00, -1.3136e+00,\n",
              "        -5.4774e-01,  2.2659e-01,  1.6819e+00,  1.1896e-01,  2.7510e-03,\n",
              "        -7.5967e-01,  7.7710e-01, -1.5769e+00, -2.3931e+00,  1.1010e+00,\n",
              "        -2.9569e-01,  8.3431e-01, -3.5149e-01,  3.6013e+00,  4.6795e-01,\n",
              "        -1.3597e+00, -9.3523e-01,  1.4022e+00, -3.4895e-01, -1.2198e+00,\n",
              "         6.8724e-02, -6.2655e-01,  9.0110e-01,  3.1488e+00,  2.5877e-01,\n",
              "         2.5003e+00,  6.7575e-01,  3.2568e-01,  5.4496e-01,  6.3934e-01,\n",
              "        -9.1743e-01, -1.1270e+00,  1.5949e+00,  1.7690e+00, -7.2414e-01,\n",
              "         2.6334e+00, -2.4303e+00,  1.9150e+00,  9.8357e-01,  8.9892e-01,\n",
              "        -2.1237e+00,  3.6107e-01,  1.6392e+00, -2.6157e+00],\n",
              "       grad_fn=<SqueezeBackward4>)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(xenc @ ws).shape"
      ],
      "metadata": {
        "id": "RjsgWVRZzQ8R",
        "outputId": "3bb42577-6505-447b-9303-8991d42b9d1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([84])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "lr = 20"
      ],
      "metadata": {
        "id": "b62zCT1yreRx"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.randn((3, 1))"
      ],
      "metadata": {
        "id": "kJYkhycyz8-p",
        "outputId": "30b660a1-8418-43ad-8c70-73054e3007a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0590],\n",
              "        [-0.4435],\n",
              "        [ 0.2357]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    xenc = functional.one_hot(xs, num_classes=vocab_len).float().flatten(start_dim=1)\n",
        "    logits = xenc @ ws\n",
        "    counts = logits.exp()\n",
        "    probs = counts / counts.sum(1, keepdim=True)\n",
        "    loss = -probs[torch.arange(int(num / 2)), ys].log().mean() + (ws.mean() * 0.01)\n",
        "    print(loss.item())\n",
        "\n",
        "    ws.grad = None\n",
        "    loss.backward()\n",
        "    ws.data += ws.grad * -lr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oohZ5r_PrqZm",
        "outputId": "ab03955f-dd1e-4d3d-9b33-4f4e5e71d197"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.588769555091858\n",
            "1.5883879661560059\n",
            "1.5880074501037598\n",
            "1.587628960609436\n",
            "1.5872516632080078\n",
            "1.5868757963180542\n",
            "1.5865012407302856\n",
            "1.5861282348632812\n",
            "1.585756778717041\n",
            "1.5853866338729858\n",
            "1.5850178003311157\n",
            "1.5846503973007202\n",
            "1.5842846632003784\n",
            "1.583919882774353\n",
            "1.5835565328598022\n",
            "1.5831944942474365\n",
            "1.5828338861465454\n",
            "1.582474708557129\n",
            "1.5821166038513184\n",
            "1.581760048866272\n",
            "1.5814045667648315\n",
            "1.5810505151748657\n",
            "1.580697774887085\n",
            "1.5803463459014893\n",
            "1.5799963474273682\n",
            "1.5796475410461426\n",
            "1.5793005228042603\n",
            "1.5789557695388794\n",
            "1.578614354133606\n",
            "1.5782774686813354\n",
            "1.5779497623443604\n",
            "1.577636480331421\n",
            "1.5773591995239258\n",
            "1.5771304368972778\n",
            "1.5770596265792847\n",
            "1.5771197080612183\n",
            "1.5779190063476562\n",
            "1.5787030458450317\n",
            "1.5828742980957031\n",
            "1.583155870437622\n",
            "1.595697045326233\n",
            "1.585252046585083\n",
            "1.6019314527511597\n",
            "1.5835095643997192\n",
            "1.5979387760162354\n",
            "1.5832946300506592\n",
            "1.5984103679656982\n",
            "1.5824345350265503\n",
            "1.59711492061615\n",
            "1.5818488597869873\n",
            "1.5965989828109741\n",
            "1.58116614818573\n",
            "1.5958120822906494\n",
            "1.5805330276489258\n",
            "1.59516441822052\n",
            "1.5798903703689575\n",
            "1.5944865942001343\n",
            "1.579260230064392\n",
            "1.5938400030136108\n",
            "1.578633189201355\n",
            "1.5931973457336426\n",
            "1.5780118703842163\n",
            "1.5925663709640503\n",
            "1.5773955583572388\n",
            "1.5919426679611206\n",
            "1.576783299446106\n",
            "1.5913258790969849\n",
            "1.5761758089065552\n",
            "1.590714931488037\n",
            "1.5755726099014282\n",
            "1.590110421180725\n",
            "1.5749733448028564\n",
            "1.5895103216171265\n",
            "1.5743783712387085\n",
            "1.588915467262268\n",
            "1.573786973953247\n",
            "1.5883253812789917\n",
            "1.5731996297836304\n",
            "1.5877394676208496\n",
            "1.572615623474121\n",
            "1.5871577262878418\n",
            "1.5720356702804565\n",
            "1.5865802764892578\n",
            "1.571459412574768\n",
            "1.5860064029693604\n",
            "1.5708867311477661\n",
            "1.5854368209838867\n",
            "1.5703177452087402\n",
            "1.5848708152770996\n",
            "1.5697516202926636\n",
            "1.5843082666397095\n",
            "1.569189429283142\n",
            "1.5837492942810059\n",
            "1.568630576133728\n",
            "1.583194375038147\n",
            "1.5680749416351318\n",
            "1.5826423168182373\n",
            "1.567522644996643\n",
            "1.5820934772491455\n",
            "1.5669740438461304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xs[:10]"
      ],
      "metadata": {
        "id": "crvU517kIuum",
        "outputId": "3b9c04f9-57d2-46a0-e0d0-2cfa6cf485a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[27, 27],\n",
              "        [27, 57],\n",
              "        [57, 26],\n",
              "        [26,  8],\n",
              "        [ 8, 48],\n",
              "        [48, 51],\n",
              "        [51,  5],\n",
              "        [ 5, 59],\n",
              "        [59, 40],\n",
              "        [40, 52]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(xs):\n",
        "  xenc = functional.one_hot(xs, num_classes=vocab_len).float().flatten(start_dim=1)\n",
        "  logits = xenc @ ws\n",
        "  counts = logits.exp()\n",
        "  probs = counts / counts.sum(1, keepdims=True)\n",
        "  outchar = itos[torch.multinomial(probs, num_samples=1).item()]\n",
        "  return outchar\n",
        "\n",
        "def prompt(ins):\n",
        "  out = ins\n",
        "  for char in range(500):\n",
        "    last_two = ins[-2:]\n",
        "    xs = torch.tensor([[stoi[last_two[0]], stoi[last_two[1]]]])\n",
        "    outs = forward(xs)\n",
        "    out += outs\n",
        "  return out\n",
        "\n",
        "prompt(\"Rom\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "koeHicLTt4Os",
        "outputId": "601598f6-84cd-4614-9a38-9cf402a50a29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Rome(_ee//i/eee<eee)ea/eecaaeea_aeeee/,_i/_eea__:_eepe_ee//aia(/eieUeaeaef\"___[e_p\"e#yeaa(ee/e/e_eH/_ee\"e_snk\"-(_/eaeVaa(//_aeaeaaea_ee/=eieiUe/ap]ee_a/a//eeiese0ee_e/_e/(ai/aey /e(e_ee/e\\\\ea_eear/(i__[_ieaaeeee__(eeuee/1pa8\"i/eaee(ee\"_e_ea(aa_HRea_/gte/neieea_a=eepea__eeeeLeii_eepeehHe_e\\\\_eae/ee\"[_eee_(wa_\\n_e__gp_eeae_/maep_e_/a(\\\\eee/e__ee__xi/_ai(e_/e/_aie_eea=/e__e)e+e/ip(/eiee(eaei_i/#/eea/(ee_apeepe=_aeeea//[ep/L{e/_ii/aei/_ne_eae_/eie\"N<e(aeaa(LaeiieaeeeG_aeaaeag(arsea_ae_eaeea(e{eepeiapeeeaey'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make test set\n",
        "xs, ys = [], []\n",
        "for data in test_set:\n",
        "  for ch1, ch2, ch3 in zip(data, data[1:], data[2:]):\n",
        "    xs.append([stoi[ch1], stoi[ch2]])\n",
        "    ys.append(stoi[ch3])\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n",
        "num = xs.nelement()\n",
        "num"
      ],
      "metadata": {
        "id": "E1aCdrq5gMg0",
        "outputId": "1117a7e5-953f-46cc-8d60-5c5d47f81eb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4196"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xenc = functional.one_hot(xs, num_classes=vocab_len).float().flatten(start_dim=1)\n",
        "logits = xenc @ ws\n",
        "counts = logits.exp()\n",
        "probs = counts / counts.sum(1, keepdim=True)\n",
        "loss = -probs[torch.arange(int(num / 2)), ys].log().mean() + (ws.mean() * 0.01)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "id": "c2U7N2msgXHI",
        "outputId": "988c4463-b745-4fb3-d84a-640a2a6ddfee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7738420963287354\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make dev set\n",
        "xs, ys = [], []\n",
        "for data in dev_set:\n",
        "  for ch1, ch2, ch3 in zip(data, data[1:], data[2:]):\n",
        "    xs.append([stoi[ch1], stoi[ch2]])\n",
        "    ys.append(stoi[ch3])\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n",
        "num = xs.nelement()\n",
        "num"
      ],
      "metadata": {
        "id": "JDMlg63jgiCx",
        "outputId": "1f591599-149a-457a-c374-5a092917fc38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3404"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xenc = functional.one_hot(xs, num_classes=vocab_len).float().flatten(start_dim=1)\n",
        "logits = xenc @ ws\n",
        "counts = logits.exp()\n",
        "probs = counts / counts.sum(1, keepdim=True)\n",
        "loss = -probs[torch.arange(int(num / 2)), ys].log().mean() + (ws.mean() * 0.01)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "id": "qgB7lKsCgjSe",
        "outputId": "ab87f8a7-c9ff-44ac-cb77-9d5484ebdf14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.5511993169784546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks like it might be overfitting? The dev set results seem fine, but the test set loss it much higher than it should be."
      ],
      "metadata": {
        "id": "a87DpLMBgrDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "lr = 20\n",
        "regularization = 0.01"
      ],
      "metadata": {
        "id": "CUeGNQeHhCso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    xenc = functional.one_hot(xs, num_classes=vocab_len).float().flatten(start_dim=1)\n",
        "    logits = xenc @ ws\n",
        "    counts = logits.exp()\n",
        "    probs = counts / counts.sum(1, keepdim=True)\n",
        "    loss = -probs[torch.arange(int(num / 2)), ys].log().mean() + (ws.mean() * regularization)\n",
        "    print(loss.item())\n",
        "\n",
        "    ws.grad = None\n",
        "    loss.backward()\n",
        "    ws.data += ws.grad * -lr"
      ],
      "metadata": {
        "id": "RO0WqQUBhGH-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}