{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Trickshotblaster/nn-practices/blob/main/TrigramLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import math"
      ],
      "metadata": {
        "id": "PiuT_51Tl7Nv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3ev7uHfxkMiG"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
        "url = 'https://raw.githubusercontent.com/karpathy/makemore/master/names.txt'\n",
        "url = 'https://raw.githubusercontent.com/Trickshotblaster/nn-practices/main/TrigramLM.ipynb'\n",
        "response = requests.get(url)\n",
        "\n",
        "with open('file.txt', 'wb') as f:\n",
        "  f.write(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('file.txt', 'r') as data:\n",
        "  dataset = data.readlines()\n",
        "\n",
        "with open('file.txt', 'r') as data:\n",
        "  raw_data = data.read()\n"
      ],
      "metadata": {
        "id": "VeY-m-Udk9vA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6b0O8l00lsV5",
        "outputId": "a8b2b9b5-87ac-457f-b933-f518299ad889"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\\n  \"nbfor'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = raw_data.split(\"\\n\")"
      ],
      "metadata": {
        "id": "94Huj2vsI8IW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMddGXOulfd7",
        "outputId": "b3d16580-b825-478e-fdaa-4e2d676fc434"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['{',\n",
              " '  \"nbformat\": 4,',\n",
              " '  \"nbformat_minor\": 0,',\n",
              " '  \"metadata\": {',\n",
              " '    \"colab\": {',\n",
              " '      \"provenance\": [],',\n",
              " '      \"include_colab_link\": true',\n",
              " '    },',\n",
              " '    \"kernelspec\": {',\n",
              " '      \"name\": \"python3\",']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = dataset[:math.floor(len(dataset) * 0.8)]\n",
        "dev_set = dataset[math.floor(len(dataset) * 0.8):math.floor(len(dataset) * 0.9)]\n",
        "test_set = dataset[math.floor(len(dataset) * 0.9):len(dataset) - 1]"
      ],
      "metadata": {
        "id": "tysnVzUhfSBI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = set(raw_data)"
      ],
      "metadata": {
        "id": "r8SisRZnmsXN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_len = len(vocab)"
      ],
      "metadata": {
        "id": "Z4j0KdGLlLZv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fq2cq6wClYmI",
        "outputId": "315750cd-21be-469d-e472-93570b25f8ff"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = {char:i for i, char in enumerate(vocab)}"
      ],
      "metadata": {
        "id": "9KA09eJhmbl2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "itos = {i:char for i, char in enumerate(vocab)}"
      ],
      "metadata": {
        "id": "RjRr7qIVm7Qx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "lRWpmX5jpbnE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as functional"
      ],
      "metadata": {
        "id": "9rCZJJKhp4LV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make dataset\n",
        "xs, ys = [], []\n",
        "for data in train_set:\n",
        "  for ch1, ch2, ch3 in zip(data, data[1:], data[2:]):\n",
        "    xs.append([stoi[ch1], stoi[ch2]])\n",
        "    ys.append(stoi[ch3])\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n",
        "num = xs.nelement()\n",
        "num"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nhNqsYvl0xm",
        "outputId": "24c61718-8206-41b9-bf00-e19fd56c3d21"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34118"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ws = torch.randn((vocab_len*2, vocab_len))\n",
        "ws.requires_grad = True\n",
        "ws.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gEB2g5WpfRE",
        "outputId": "2ce0deeb-4408-4a82-88a2-6d80906b34ed"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([172, 86])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xenc = functional.one_hot(xs[0], num_classes=vocab_len).float().flatten()\n",
        "xenc @ ws"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2cwT-tEpvpL",
        "outputId": "80739fa3-20e3-4c8d-e6c2-73629c5fb40a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.0794,  1.8022,  1.9395, -0.5692,  0.0620, -3.7957, -1.0224, -1.3213,\n",
              "        -0.5041, -0.2540, -1.3792,  1.5899,  1.5425,  0.4421,  1.6314, -0.5042,\n",
              "         0.3970, -0.0475, -0.2891, -0.0353, -1.7860,  2.1028,  0.2761, -1.5458,\n",
              "        -0.1144,  0.9313,  0.5265, -0.2161,  0.1975,  0.1169, -0.7408, -2.0907,\n",
              "        -0.2515, -0.7268,  1.3164, -0.8426,  0.2475, -0.2823,  1.1661,  0.9416,\n",
              "         1.4624, -0.5405, -1.9547,  0.0190, -0.4224, -1.7860, -0.9386, -0.7907,\n",
              "         1.1146,  1.5420,  0.2392,  2.6738,  0.5329,  1.1459, -0.3995, -0.2969,\n",
              "        -0.9814,  0.9496,  1.5875, -1.1933,  2.0189,  0.7296,  0.8806,  0.7074,\n",
              "         0.7530, -2.6069, -1.8081,  0.1439, -2.0136, -1.4745, -0.3157,  2.2345,\n",
              "         1.3309, -0.6457,  1.4138, -0.2124,  0.3019, -0.5609,  0.3886, -2.0784,\n",
              "         1.1653, -0.4307,  1.0796, -1.3916,  0.7843,  0.1512],\n",
              "       grad_fn=<SqueezeBackward4>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(xenc @ ws).shape"
      ],
      "metadata": {
        "id": "RjsgWVRZzQ8R",
        "outputId": "0e16cc3c-105f-48bf-d6b7-1ac22053d0d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([86])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "lr = 20"
      ],
      "metadata": {
        "id": "b62zCT1yreRx"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.randn((3, 1))"
      ],
      "metadata": {
        "id": "kJYkhycyz8-p",
        "outputId": "bf1a1a15-f481-46e6-8442-80e2fbbd9737",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.4632],\n",
              "        [0.3529],\n",
              "        [1.5197]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "\n",
        "    xenc = functional.one_hot(xs, num_classes=vocab_len).float().flatten(start_dim=1)\n",
        "    logits = xenc @ ws\n",
        "    counts = logits.exp()\n",
        "    probs = counts / counts.sum(1, keepdim=True)\n",
        "    loss = -probs[torch.arange(int(num / 2)), ys].log().mean() + (ws.mean() * 0.01)\n",
        "    print(loss.item())\n",
        "\n",
        "    ws.grad = None\n",
        "    loss.backward()\n",
        "    ws.data += ws.grad * -lr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oohZ5r_PrqZm",
        "outputId": "f71e47e5-279f-4bdc-e901-d8db27507b88"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.968534469604492\n",
            "4.1083598136901855\n",
            "3.842843532562256\n",
            "3.6717939376831055\n",
            "3.5867834091186523\n",
            "3.510815382003784\n",
            "3.4395248889923096\n",
            "3.3759772777557373\n",
            "3.314143419265747\n",
            "3.2641849517822266\n",
            "3.208268404006958\n",
            "3.170440196990967\n",
            "3.1164026260375977\n",
            "3.085538387298584\n",
            "3.0354416370391846\n",
            "3.009063959121704\n",
            "2.963214635848999\n",
            "2.9405465126037598\n",
            "2.8979837894439697\n",
            "2.878469705581665\n",
            "2.8386282920837402\n",
            "2.8218278884887695\n",
            "2.7843074798583984\n",
            "2.769847869873047\n",
            "2.7343356609344482\n",
            "2.721897602081299\n",
            "2.6881449222564697\n",
            "2.6774637699127197\n",
            "2.6452724933624268\n",
            "2.636132001876831\n",
            "2.60534405708313\n",
            "2.5975711345672607\n",
            "2.5680596828460693\n",
            "2.5615155696868896\n",
            "2.533174753189087\n",
            "2.527745246887207\n",
            "2.5004818439483643\n",
            "2.4960715770721436\n",
            "2.469801187515259\n",
            "2.4663264751434326\n",
            "2.4409706592559814\n",
            "2.438354730606079\n",
            "2.41383957862854\n",
            "2.4120116233825684\n",
            "2.388268232345581\n",
            "2.3871634006500244\n",
            "2.3641257286071777\n",
            "2.363682270050049\n",
            "2.3412930965423584\n",
            "2.34145450592041\n",
            "2.3196609020233154\n",
            "2.320375680923462\n",
            "2.2991323471069336\n",
            "2.300353527069092\n",
            "2.279618740081787\n",
            "2.281303644180298\n",
            "2.261042833328247\n",
            "2.263153314590454\n",
            "2.243335008621216\n",
            "2.2458372116088867\n",
            "2.226433038711548\n",
            "2.229297637939453\n",
            "2.21028208732605\n",
            "2.213482141494751\n",
            "2.1948320865631104\n",
            "2.1983439922332764\n",
            "2.1800386905670166\n",
            "2.1838414669036865\n",
            "2.1658616065979004\n",
            "2.169936180114746\n",
            "2.1522648334503174\n",
            "2.1565945148468018\n",
            "2.1392147541046143\n",
            "2.1437838077545166\n",
            "2.126680612564087\n",
            "2.1314749717712402\n",
            "2.114635467529297\n",
            "2.119643211364746\n",
            "2.103052854537964\n",
            "2.1082615852355957\n",
            "2.0919084548950195\n",
            "2.09730863571167\n",
            "2.081181287765503\n",
            "2.086761951446533\n",
            "2.0708494186401367\n",
            "2.0766022205352783\n",
            "2.06089448928833\n",
            "2.066810369491577\n",
            "2.051297903060913\n",
            "2.057368278503418\n",
            "2.042041301727295\n",
            "2.0482594966888428\n",
            "2.033109664916992\n",
            "2.039468765258789\n",
            "2.0244874954223633\n",
            "2.030980110168457\n",
            "2.0161592960357666\n",
            "2.022779941558838\n",
            "2.008112907409668\n",
            "2.014855146408081\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xs[:10]"
      ],
      "metadata": {
        "id": "crvU517kIuum",
        "outputId": "33dd8203-2c02-4fa9-8290-c7c85313e2d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[53, 53],\n",
              "        [53, 13],\n",
              "        [13, 43],\n",
              "        [43, 26],\n",
              "        [26,  9],\n",
              "        [ 9,  2],\n",
              "        [ 2, 75],\n",
              "        [75, 73],\n",
              "        [73, 74],\n",
              "        [74, 38]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(xs):\n",
        "  xenc = functional.one_hot(xs, num_classes=vocab_len).float().flatten(start_dim=1)\n",
        "  logits = xenc @ ws\n",
        "  counts = logits.exp()\n",
        "  probs = counts / counts.sum(1, keepdims=True)\n",
        "  outchar = itos[torch.multinomial(probs, num_samples=1).item()]\n",
        "  return outchar\n",
        "\n",
        "def prompt(ins):\n",
        "  out = ins\n",
        "  for char in range(500):\n",
        "    last_two = ins[-2:]\n",
        "    xs = torch.tensor([[stoi[last_two[0]], stoi[last_two[1]]]])\n",
        "    outs = forward(xs)\n",
        "    out += outs\n",
        "  return out\n",
        "\n",
        "prompt(\"Rom\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "koeHicLTt4Os",
        "outputId": "ce08f964-e41d-42ec-efe2-0aee91168c05"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Romrkrw\"eae[ieaee__@,vee_\\newteer_rdr*seeLSe:iaeUseevs_BwaaeUreraear_ea}IaiOaeeaaUiaea_aaerz_eeegeai_asa_Uea[.aee[a[eie.Leaerre@<eeQa_e_eTrkImee_sreks)a_66eUr_[eu_er<a_aer_rCeE___1a_ere__erea_eaeeaiaOeee)Is[iieese[ee_v-aa_iaaeea_aa/[e/Ueeke_aa_eGai<iea_v8eaeeae__ex_Ce[__eVO/[[eaeeeQu_eeesieBad7xac/i[as__retDeeUe?re_a[aeevrVreeC[ear_e0ieUacrBXro_eaLe[eeQeeecGvC[DU_\"iaueem_aeC_re/ea eeeee1e[6Sia aeaa[9e5evaC__L<ee2[aaEeeeiiWev[=Oe[_[_B_eweeaaa_a_ae_[rsieeei_ee0eeDaD\"asne[[sXe<W_are_[araevhveLLXasDeaBr'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make test set\n",
        "xs, ys = [], []\n",
        "for data in test_set:\n",
        "  for ch1, ch2, ch3 in zip(data, data[1:], data[2:]):\n",
        "    xs.append([stoi[ch1], stoi[ch2]])\n",
        "    ys.append(stoi[ch3])\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n",
        "num = xs.nelement()\n",
        "num"
      ],
      "metadata": {
        "id": "E1aCdrq5gMg0",
        "outputId": "4350c136-76c6-4b99-a9cf-2b63cc707a55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3936"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xenc = functional.one_hot(xs, num_classes=vocab_len).float().flatten(start_dim=1)\n",
        "logits = xenc @ ws\n",
        "counts = logits.exp()\n",
        "probs = counts / counts.sum(1, keepdim=True)\n",
        "loss = -probs[torch.arange(int(num / 2)), ys].log().mean() + (ws.mean() * 0.01)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "id": "c2U7N2msgXHI",
        "outputId": "d2ad26b8-8131-4f85-cbcb-40b7c52ad6ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4101316928863525\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make dev set\n",
        "xs, ys = [], []\n",
        "for data in dev_set:\n",
        "  for ch1, ch2, ch3 in zip(data, data[1:], data[2:]):\n",
        "    xs.append([stoi[ch1], stoi[ch2]])\n",
        "    ys.append(stoi[ch3])\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n",
        "num = xs.nelement()\n",
        "num"
      ],
      "metadata": {
        "id": "JDMlg63jgiCx",
        "outputId": "7040fc8d-6362-490e-ab22-442b00520550",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3850"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xenc = functional.one_hot(xs, num_classes=vocab_len).float().flatten(start_dim=1)\n",
        "logits = xenc @ ws\n",
        "counts = logits.exp()\n",
        "probs = counts / counts.sum(1, keepdim=True)\n",
        "loss = -probs[torch.arange(int(num / 2)), ys].log().mean() + (ws.mean() * 0.01)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "id": "qgB7lKsCgjSe",
        "outputId": "4d5ea222-f656-4200-dfd1-2dc99b14d857",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1572365760803223\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks like it might be overfitting? The dev set results seem fine, but the test set loss it much higher than it should be."
      ],
      "metadata": {
        "id": "a87DpLMBgrDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make dev set\n",
        "dxs, dys = [], []\n",
        "for data in dev_set:\n",
        "  for ch1, ch2, ch3 in zip(data, data[1:], data[2:]):\n",
        "    dxs.append([stoi[ch1], stoi[ch2]])\n",
        "    dys.append(stoi[ch3])\n",
        "\n",
        "dxs = torch.tensor(xs)\n",
        "dys = torch.tensor(ys)\n",
        "dnum = xs.nelement()\n",
        "dnum"
      ],
      "metadata": {
        "id": "WoEddjEPiRJX",
        "outputId": "f52ddf9e-dd4b-449e-d7f8-433236560f73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-af72f93a7454>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  dxs = torch.tensor(xs)\n",
            "<ipython-input-33-af72f93a7454>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  dys = torch.tensor(ys)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3850"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "lr = 20\n",
        "regularization = 0.01"
      ],
      "metadata": {
        "id": "CUeGNQeHhCso"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = 2.1\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    dxenc = functional.one_hot(dxs, num_classes=vocab_len).float().flatten(start_dim=1)\n",
        "    dlogits = dxenc @ ws\n",
        "    dcounts = dlogits.exp()\n",
        "    dprobs = dcounts / dcounts.sum(1, keepdim=True)\n",
        "    dloss = -dprobs[torch.arange(int(num / 2)), dys].log().mean() + (ws.mean() * regularization)\n",
        "    dloss.detach()\n",
        "\n",
        "    xenc = functional.one_hot(xs, num_classes=vocab_len).float().flatten(start_dim=1)\n",
        "    logits = xenc @ ws\n",
        "    counts = logits.exp()\n",
        "    probs = counts / counts.sum(1, keepdim=True)\n",
        "    loss = -probs[torch.arange(int(num / 2)), ys].log().mean() + (ws.mean() * regularization * (abs(loss - dloss)))\n",
        "    print(loss.item())\n",
        "    ws.grad = None\n",
        "    loss.backward()\n",
        "    ws.data += ws.grad * -lr"
      ],
      "metadata": {
        "id": "RO0WqQUBhGH-",
        "outputId": "ba5660c9-60aa-43a3-c015-59caba7fdad1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.2260608673095703\n",
            "1.234903335571289\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-ecccfca502db>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
          ]
        }
      ]
    }
  ]
}