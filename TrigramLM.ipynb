{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Trickshotblaster/nn-practices/blob/main/TrigramLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import math"
      ],
      "metadata": {
        "id": "PiuT_51Tl7Nv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3ev7uHfxkMiG"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
        "url = 'https://raw.githubusercontent.com/karpathy/makemore/master/names.txt'\n",
        "url = 'https://raw.githubusercontent.com/Trickshotblaster/nn-practices/main/TrigramLM.ipynb'\n",
        "response = requests.get(url)\n",
        "\n",
        "with open('file.txt', 'wb') as f:\n",
        "  f.write(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('file.txt', 'r') as data:\n",
        "  dataset = data.readlines()\n",
        "\n",
        "with open('file.txt', 'r') as data:\n",
        "  raw_data = data.read()\n"
      ],
      "metadata": {
        "id": "VeY-m-Udk9vA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6b0O8l00lsV5",
        "outputId": "f372ab72-9db1-418c-9425-1546d679d1d8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\\n  \"nbfor'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = raw_data.split(\"\\n\")"
      ],
      "metadata": {
        "id": "94Huj2vsI8IW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMddGXOulfd7",
        "outputId": "4fadfaf9-9d41-4aef-bd24-1c685ec0e1d7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['{',\n",
              " '  \"nbformat\": 4,',\n",
              " '  \"nbformat_minor\": 0,',\n",
              " '  \"metadata\": {',\n",
              " '    \"colab\": {',\n",
              " '      \"provenance\": [],',\n",
              " '      \"include_colab_link\": true',\n",
              " '    },',\n",
              " '    \"kernelspec\": {',\n",
              " '      \"name\": \"python3\",']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = set(raw_data)"
      ],
      "metadata": {
        "id": "r8SisRZnmsXN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_len = len(vocab)"
      ],
      "metadata": {
        "id": "Z4j0KdGLlLZv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fq2cq6wClYmI",
        "outputId": "0e7594cb-484c-489e-aa42-ba2f34f2f3ab"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = {char:i for i, char in enumerate(vocab)}"
      ],
      "metadata": {
        "id": "9KA09eJhmbl2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "itos = {i:char for i, char in enumerate(vocab)}"
      ],
      "metadata": {
        "id": "RjRr7qIVm7Qx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "lRWpmX5jpbnE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as functional"
      ],
      "metadata": {
        "id": "9rCZJJKhp4LV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make dataset\n",
        "xs, ys = [], []\n",
        "for data in dataset:\n",
        "  for ch1, ch2, ch3 in zip(data, data[1:], data[2:]):\n",
        "    xs.append([stoi[ch1], stoi[ch2]])\n",
        "    ys.append(stoi[ch3])\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n",
        "num = xs.nelement()\n",
        "num"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nhNqsYvl0xm",
        "outputId": "fb536f72-ef07-4a10-ae04-ce25b75bc0c1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29898"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ws = torch.randn((vocab_len*2, vocab_len))\n",
        "ws.requires_grad = True\n",
        "ws.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gEB2g5WpfRE",
        "outputId": "0f3126d9-5f01-4eb2-8b55-ce4378c83e1a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([168, 84])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xenc = functional.one_hot(xs[0], num_classes=vocab_len).float().flatten()\n",
        "xenc @ ws"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2cwT-tEpvpL",
        "outputId": "e2e353cf-1c55-48ed-bb87-33e7bc1b7539"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.2902, -1.0448, -0.4287,  2.6370,  0.7902,  1.8763,  1.7406,  0.1233,\n",
              "         0.4230, -0.0459,  0.9820,  1.2457,  1.2672, -1.6317,  0.5418,  1.6025,\n",
              "        -1.1339, -1.7975, -1.1677, -1.0376, -1.5510,  1.3972,  0.9162, -1.7395,\n",
              "        -0.1500, -0.6401, -3.6267,  1.2203, -1.0166,  1.2318,  1.0518,  1.0120,\n",
              "        -0.0308,  0.8081,  4.1057,  0.3306, -2.2938,  0.6392, -1.9167, -1.7486,\n",
              "        -0.0802,  0.0229, -0.1797, -1.2204,  0.9249,  0.0404, -1.0170,  0.4987,\n",
              "        -0.5868, -1.1132, -2.7369, -0.2905, -2.0242,  1.2513,  0.5900, -3.2943,\n",
              "        -0.0060, -2.5865,  1.1640, -0.3444, -0.2656, -0.0652, -1.7462,  1.2464,\n",
              "         2.6086, -0.2733, -2.9515, -0.3248,  0.4784, -1.4727,  1.5851, -1.8234,\n",
              "        -0.4941, -0.2109,  0.7347,  0.3523,  0.8111,  1.0197,  0.7730,  1.0821,\n",
              "        -1.3962, -1.3378, -0.0523, -0.6386], grad_fn=<SqueezeBackward4>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(xenc @ ws).shape"
      ],
      "metadata": {
        "id": "RjsgWVRZzQ8R",
        "outputId": "f43d0624-0d39-49c2-d97e-f1bd8c8fef27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([84])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "lr = 50"
      ],
      "metadata": {
        "id": "b62zCT1yreRx"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.randn((3, 1))"
      ],
      "metadata": {
        "id": "kJYkhycyz8-p",
        "outputId": "7ef68d81-b82e-4aa6-855f-40c8bb41a3ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-4.0799e-01],\n",
              "        [ 7.8032e-01],\n",
              "        [-2.7628e-04]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    xenc = functional.one_hot(xs, num_classes=vocab_len).float().flatten(start_dim=1)\n",
        "    logits = xenc @ ws\n",
        "    counts = logits.exp()\n",
        "    probs = counts / counts.sum(1, keepdim=True)\n",
        "    loss = -probs[torch.arange(int(num / 2)), ys].log().mean() + (ws.mean() * 0.01)\n",
        "    print(loss.item())\n",
        "\n",
        "    ws.grad = None\n",
        "    loss.backward()\n",
        "    ws.data += ws.grad * -lr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oohZ5r_PrqZm",
        "outputId": "b72048e6-78b8-4f0a-8c67-8e280c82dfb2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6528780460357666\n",
            "2.2465128898620605\n",
            "1.9401931762695312\n",
            "1.830486536026001\n",
            "1.8050857782363892\n",
            "2.016796827316284\n",
            "3.191267251968384\n",
            "2.566632032394409\n",
            "2.165956974029541\n",
            "1.8682912588119507\n",
            "1.7715778350830078\n",
            "1.7477238178253174\n",
            "2.0528206825256348\n",
            "3.348189353942871\n",
            "2.6920411586761475\n",
            "2.279139757156372\n",
            "1.9513193368911743\n",
            "1.8941682577133179\n",
            "2.1152594089508057\n",
            "1.7816951274871826\n",
            "2.1447243690490723\n",
            "3.613374948501587\n",
            "2.898707151412964\n",
            "2.464660882949829\n",
            "2.105971097946167\n",
            "1.964372992515564\n",
            "2.115729570388794\n",
            "1.7882946729660034\n",
            "1.9539504051208496\n",
            "3.036581516265869\n",
            "2.485316276550293\n",
            "2.0953667163848877\n",
            "1.80934476852417\n",
            "1.7199320793151855\n",
            "1.6941883563995361\n",
            "1.8263765573501587\n",
            "2.6621742248535156\n",
            "2.1984660625457764\n",
            "1.849191427230835\n",
            "1.8120577335357666\n",
            "2.2026803493499756\n",
            "1.8201344013214111\n",
            "2.067568778991699\n",
            "3.55387282371521\n",
            "2.8189685344696045\n",
            "2.387122392654419\n",
            "2.0307488441467285\n",
            "1.8686105012893677\n",
            "1.9752391576766968\n",
            "1.6844390630722046\n",
            "1.8741793632507324\n",
            "2.9126222133636475\n",
            "2.3812646865844727\n",
            "2.0094058513641357\n",
            "1.7828627824783325\n",
            "1.7768479585647583\n",
            "1.880489706993103\n",
            "2.917100191116333\n",
            "2.3771555423736572\n",
            "2.0057339668273926\n",
            "1.7649294137954712\n",
            "1.7216718196868896\n",
            "1.957755208015442\n",
            "3.116267681121826\n",
            "2.5066306591033936\n",
            "2.1168816089630127\n",
            "1.808327555656433\n",
            "1.7541254758834839\n",
            "1.9323025941848755\n",
            "1.675941824913025\n",
            "1.682866096496582\n",
            "2.083259344100952\n",
            "3.5251669883728027\n",
            "2.814458131790161\n",
            "2.393634796142578\n",
            "2.042243242263794\n",
            "1.9380214214324951\n",
            "2.1685028076171875\n",
            "1.8207279443740845\n",
            "1.7639319896697998\n",
            "2.4468491077423096\n",
            "2.0406856536865234\n",
            "1.7278932332992554\n",
            "1.7970646619796753\n",
            "2.4308922290802\n",
            "1.9766649007797241\n",
            "1.6681573390960693\n",
            "2.0047950744628906\n",
            "3.367171287536621\n",
            "2.684199333190918\n",
            "2.2799041271209717\n",
            "1.9436235427856445\n",
            "1.8977540731430054\n",
            "2.2012157440185547\n",
            "1.842176914215088\n",
            "1.7707558870315552\n",
            "2.4789981842041016\n",
            "2.0636813640594482\n",
            "1.7411729097366333\n",
            "1.8072333335876465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xs[:10]"
      ],
      "metadata": {
        "id": "crvU517kIuum",
        "outputId": "ab5f3c90-0a06-4b6c-fcae-09071c332a4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[30, 30],\n",
              "        [30, 60],\n",
              "        [60, 26],\n",
              "        [26,  6],\n",
              "        [ 6, 37],\n",
              "        [37,  7],\n",
              "        [ 7, 33],\n",
              "        [33, 58],\n",
              "        [58, 64],\n",
              "        [64, 53]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(xs):\n",
        "  xenc = functional.one_hot(xs, num_classes=vocab_len).float().flatten(start_dim=1)\n",
        "  logits = xenc @ ws\n",
        "  counts = logits.exp()\n",
        "  probs = counts / counts.sum(1, keepdims=True)\n",
        "  outchar = itos[torch.multinomial(probs, num_samples=1).item()]\n",
        "  return outchar\n",
        "\n",
        "def prompt(ins):\n",
        "  out = ins\n",
        "  for char in range(500):\n",
        "    last_two = ins[-2:]\n",
        "    xs = torch.tensor([[stoi[last_two[0]], stoi[last_two[1]]]])\n",
        "    outs = forward(xs)\n",
        "    out += outs\n",
        "  return out\n",
        "\n",
        "prompt(\"Rom\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "koeHicLTt4Os",
        "outputId": "601598f6-84cd-4614-9a38-9cf402a50a29"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Rome(_ee//i/eee<eee)ea/eecaaeea_aeeee/,_i/_eea__:_eepe_ee//aia(/eieUeaeaef\"___[e_p\"e#yeaa(ee/e/e_eH/_ee\"e_snk\"-(_/eaeVaa(//_aeaeaaea_ee/=eieiUe/ap]ee_a/a//eeiese0ee_e/_e/(ai/aey /e(e_ee/e\\\\ea_eear/(i__[_ieaaeeee__(eeuee/1pa8\"i/eaee(ee\"_e_ea(aa_HRea_/gte/neieea_a=eepea__eeeeLeii_eepeehHe_e\\\\_eae/ee\"[_eee_(wa_\\n_e__gp_eeae_/maep_e_/a(\\\\eee/e__ee__xi/_ai(e_/e/_aie_eea=/e__e)e+e/ip(/eiee(eaei_i/#/eea/(ee_apeepe=_aeeea//[ep/L{e/_ii/aei/_ne_eae_/eie\"N<e(aeaa(LaeiieaeeeG_aeaaeag(arsea_ae_eaeea(e{eepeiapeeeaey'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}