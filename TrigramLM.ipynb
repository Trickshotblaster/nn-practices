{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Trickshotblaster/nn-practices/blob/main/TrigramLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import math"
      ],
      "metadata": {
        "id": "PiuT_51Tl7Nv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3ev7uHfxkMiG"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
        "url = 'https://raw.githubusercontent.com/karpathy/makemore/master/names.txt'\n",
        "#url = 'https://raw.githubusercontent.com/Trickshotblaster/nn-practices/main/TrigramLM.ipynb'\n",
        "response = requests.get(url)\n",
        "\n",
        "with open('file.txt', 'wb') as f:\n",
        "  f.write(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('file.txt', 'r') as data:\n",
        "  dataset = data.readlines()\n",
        "\n",
        "with open('file.txt', 'r') as data:\n",
        "  raw_data = data.read()\n"
      ],
      "metadata": {
        "id": "VeY-m-Udk9vA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = raw_data.split(\"\\n\")"
      ],
      "metadata": {
        "id": "94Huj2vsI8IW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMddGXOulfd7",
        "outputId": "2ab7d0b0-642d-4b85-d229-6d4b3ddfaa32"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['emma',\n",
              " 'olivia',\n",
              " 'ava',\n",
              " 'isabella',\n",
              " 'sophia',\n",
              " 'charlotte',\n",
              " 'mia',\n",
              " 'amelia',\n",
              " 'harper',\n",
              " 'evelyn']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, data in enumerate(dataset):\n",
        "  dataset[i] = \".\" + data + \".\""
      ],
      "metadata": {
        "id": "iAKuZ0EotAvh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EQ62S6JtHBF",
        "outputId": "aee9a829-f018-437d-b772-eec44a3ec8be"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.emma.',\n",
              " '.olivia.',\n",
              " '.ava.',\n",
              " '.isabella.',\n",
              " '.sophia.',\n",
              " '.charlotte.',\n",
              " '.mia.',\n",
              " '.amelia.',\n",
              " '.harper.',\n",
              " '.evelyn.']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data = ''.join(dataset)"
      ],
      "metadata": {
        "id": "6b0O8l00lsV5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "V45hY8_ot7RS",
        "outputId": "78867052-7b5d-4e9f-997d-9939acb653ea"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'.emma..oli'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = dataset[:math.floor(len(dataset) * 0.8)]\n",
        "dev_set = dataset[math.floor(len(dataset) * 0.8):math.floor(len(dataset) * 0.9)]\n",
        "test_set = dataset[math.floor(len(dataset) * 0.9):len(dataset) - 1]"
      ],
      "metadata": {
        "id": "tysnVzUhfSBI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set[:10]"
      ],
      "metadata": {
        "id": "gclHeZg7w6tC",
        "outputId": "c9dc6f94-564d-45dc-ee65-298f7bf73e7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.emma.',\n",
              " '.olivia.',\n",
              " '.ava.',\n",
              " '.isabella.',\n",
              " '.sophia.',\n",
              " '.charlotte.',\n",
              " '.mia.',\n",
              " '.amelia.',\n",
              " '.harper.',\n",
              " '.evelyn.']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_set[:10]"
      ],
      "metadata": {
        "id": "tFQGzNUpw9q7",
        "outputId": "bd3b7237-b64c-49e9-cb00-6c56c5b20b7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.amrom.',\n",
              " '.aniket.',\n",
              " '.ansen.',\n",
              " '.apolo.',\n",
              " '.aqib.',\n",
              " '.aquarius.',\n",
              " '.araf.',\n",
              " '.arafat.',\n",
              " '.areeb.',\n",
              " '.ariez.']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_set[:10]"
      ],
      "metadata": {
        "id": "3ZjMG1N6xAa6",
        "outputId": "1f857c4c-b97d-4628-e7da-7b971bb5ebfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.arib.',\n",
              " '.arinze.',\n",
              " '.aristeo.',\n",
              " '.arlind.',\n",
              " '.armahni.',\n",
              " '.arnez.',\n",
              " '.arnie.',\n",
              " '.arrie.',\n",
              " '.arris.',\n",
              " '.arrison.']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = set(raw_data)"
      ],
      "metadata": {
        "id": "r8SisRZnmsXN"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMmItrNTtm_F",
        "outputId": "62a068df-5b86-4cbe-f6da-a8b3d8aad673"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_len = len(vocab)"
      ],
      "metadata": {
        "id": "Z4j0KdGLlLZv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fq2cq6wClYmI",
        "outputId": "0d68fef4-e6b9-48b6-d89d-5271e2bfcc97"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = {char:i for i, char in enumerate(vocab)}"
      ],
      "metadata": {
        "id": "9KA09eJhmbl2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "itos = {i:char for i, char in enumerate(vocab)}"
      ],
      "metadata": {
        "id": "RjRr7qIVm7Qx"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "lRWpmX5jpbnE"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as functional"
      ],
      "metadata": {
        "id": "9rCZJJKhp4LV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make dataset\n",
        "xs, ys = [], []\n",
        "for data in train_set:\n",
        "  for ch1, ch2, ch3 in zip(data, data[1:], data[2:]):\n",
        "    xs.append([stoi[ch1], stoi[ch2]])\n",
        "    ys.append(stoi[ch3])\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n",
        "num = xs.nelement()\n",
        "num"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nhNqsYvl0xm",
        "outputId": "7f2fc5fd-80b6-46ad-f159-c31c68c918bb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "314304"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ws = torch.randn((vocab_len*2, vocab_len))\n",
        "ws.requires_grad = True\n",
        "ws.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gEB2g5WpfRE",
        "outputId": "7f2cb931-37f9-4a19-8498-bdb313540463"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([54, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xenc = functional.one_hot(xs[0], num_classes=vocab_len).float().flatten()\n",
        "xenc @ ws"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2cwT-tEpvpL",
        "outputId": "1c746f0a-6b7b-465a-f455-ac121277cf1c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.1914,  1.3921, -0.1388, -0.2208,  0.2059,  1.4562, -0.2593,  1.1706,\n",
              "         1.4966,  0.1358,  1.4122, -1.7554,  0.0558, -1.1877, -0.7734,  1.3158,\n",
              "         0.3693, -0.7533, -2.7516,  2.3409,  1.9801, -2.1097,  0.1785,  0.0876,\n",
              "         1.0513, -2.3817, -1.4019], grad_fn=<SqueezeBackward4>)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(xenc @ ws).shape"
      ],
      "metadata": {
        "id": "RjsgWVRZzQ8R",
        "outputId": "42e55d42-bf3b-486e-d54d-4a6188684740",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([27])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "lr = 20"
      ],
      "metadata": {
        "id": "b62zCT1yreRx"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.randn((3, 1))"
      ],
      "metadata": {
        "id": "kJYkhycyz8-p",
        "outputId": "5022d694-66a6-4fea-f939-c59e653d6a6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1656],\n",
              "        [-1.4990],\n",
              "        [ 0.6609]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "\n",
        "    xenc = functional.one_hot(xs, num_classes=vocab_len).float().flatten(start_dim=1)\n",
        "    logits = xenc @ ws\n",
        "    counts = logits.exp()\n",
        "    probs = counts / counts.sum(1, keepdim=True)\n",
        "    loss = -probs[torch.arange(int(num / 2)), ys].log().mean() + (ws.mean() * 0.01)\n",
        "    print(loss.item())\n",
        "\n",
        "    ws.grad = None\n",
        "    loss.backward()\n",
        "    ws.data += ws.grad * -lr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oohZ5r_PrqZm",
        "outputId": "8fcf9b14-2e0e-4daa-8383-8b075fb86cc9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.159309387207031\n",
            "3.7566850185394287\n",
            "3.461942195892334\n",
            "3.2559168338775635\n",
            "3.109874725341797\n",
            "2.999500036239624\n",
            "2.9123246669769287\n",
            "2.842172145843506\n",
            "2.7850067615509033\n",
            "2.73781681060791\n",
            "2.698340654373169\n",
            "2.6648833751678467\n",
            "2.6361703872680664\n",
            "2.611236095428467\n",
            "2.5893478393554688\n",
            "2.569944381713867\n",
            "2.5525922775268555\n",
            "2.5369532108306885\n",
            "2.522759437561035\n",
            "2.5097975730895996\n",
            "2.497894763946533\n",
            "2.486910104751587\n",
            "2.476729393005371\n",
            "2.4672577381134033\n",
            "2.4584157466888428\n",
            "2.450136423110962\n",
            "2.44236421585083\n",
            "2.4350502490997314\n",
            "2.4281532764434814\n",
            "2.4216365814208984\n",
            "2.4154696464538574\n",
            "2.4096240997314453\n",
            "2.4040756225585938\n",
            "2.398801803588867\n",
            "2.3937833309173584\n",
            "2.3890023231506348\n",
            "2.3844428062438965\n",
            "2.380089521408081\n",
            "2.375929594039917\n",
            "2.371950626373291\n",
            "2.3681414127349854\n",
            "2.3644912242889404\n",
            "2.3609907627105713\n",
            "2.357630729675293\n",
            "2.354403257369995\n",
            "2.3513004779815674\n",
            "2.3483152389526367\n",
            "2.345440626144409\n",
            "2.3426713943481445\n",
            "2.340000867843628\n",
            "2.3374245166778564\n",
            "2.3349366188049316\n",
            "2.3325328826904297\n",
            "2.3302090167999268\n",
            "2.327960729598999\n",
            "2.325784921646118\n",
            "2.3236773014068604\n",
            "2.3216347694396973\n",
            "2.319654703140259\n",
            "2.3177337646484375\n",
            "2.3158693313598633\n",
            "2.3140594959259033\n",
            "2.312300682067871\n",
            "2.310591459274292\n",
            "2.308929920196533\n",
            "2.3073132038116455\n",
            "2.3057408332824707\n",
            "2.3042094707489014\n",
            "2.3027188777923584\n",
            "2.301266670227051\n",
            "2.299851655960083\n",
            "2.2984724044799805\n",
            "2.2971274852752686\n",
            "2.2958154678344727\n",
            "2.2945356369018555\n",
            "2.2932863235473633\n",
            "2.292067527770996\n",
            "2.290876865386963\n",
            "2.2897140979766846\n",
            "2.2885780334472656\n",
            "2.287468194961548\n",
            "2.2863833904266357\n",
            "2.285322427749634\n",
            "2.284285306930542\n",
            "2.283270835876465\n",
            "2.282278060913086\n",
            "2.2813069820404053\n",
            "2.2803564071655273\n",
            "2.279426097869873\n",
            "2.278515338897705\n",
            "2.277623176574707\n",
            "2.2767493724823\n",
            "2.275893449783325\n",
            "2.275054931640625\n",
            "2.274233102798462\n",
            "2.2734272480010986\n",
            "2.272637367248535\n",
            "2.2718632221221924\n",
            "2.271103620529175\n",
            "2.2703588008880615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xs[:10]"
      ],
      "metadata": {
        "id": "crvU517kIuum",
        "outputId": "f83f0273-48ed-4143-b078-982bfd2e1f8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0, 22],\n",
              "        [22,  2],\n",
              "        [ 2,  2],\n",
              "        [ 2, 20],\n",
              "        [ 0, 17],\n",
              "        [17, 10],\n",
              "        [10, 21],\n",
              "        [21, 24],\n",
              "        [24, 21],\n",
              "        [21, 20]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(xs):\n",
        "  xenc = functional.one_hot(xs, num_classes=vocab_len).float().flatten(start_dim=1)\n",
        "  logits = xenc @ ws\n",
        "  counts = logits.exp()\n",
        "  probs = counts / counts.sum(1, keepdims=True)\n",
        "  outchar = itos[torch.multinomial(probs, num_samples=1).item()]\n",
        "  return outchar\n",
        "\n",
        "def prompt(ins):\n",
        "  out = ins\n",
        "  for char in range(500):\n",
        "    last_two = ins[-2:]\n",
        "    xs = torch.tensor([[stoi[last_two[0]], stoi[last_two[1]]]])\n",
        "    outs = forward(xs)\n",
        "    out += outs\n",
        "  return out\n",
        "\n",
        "prompt(\"Rom\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "koeHicLTt4Os",
        "outputId": "a4a9ae16-a558-494d-9ffa-17a3b831e1b5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Romeiaiikeia.ba.iiifanaiii.ayaiaem.iamaia.aaioieiifa.ioenafieiee.imiafo.uieoelaaaa.aaieyoa.aaaayiiaaieaaewa..eiriaz.aia.eeaaimia..iaianaaafiecaaame.efr.abailayiauaiykeaiayaieiaiaaismreaaefaeaa..eet.iaioa.abiubeyaai.aqiaaiin.aaietivui..afaeyaaaafrea..aieabae.ie.xe.aiimycr.aaea.d.iaaieiirbkeeaiabaieaervwxiaeu..ecybaaaaainaleioay.eaaiyaaa.aeioaeiaiatmhmaiaaeeikqiaioeaai.o.iebaaaieaiimaaafaaovaieffayaaaaeeiieaimyairyiaaimiaiai.aieoaafaaaei..oiiafcoueii.eae.x..eaiyba.aiyeaaiaiieaaa.eeaaaieiaaimi.iii.iei'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make test set\n",
        "txs, tys = [], []\n",
        "for data in test_set:\n",
        "  for ch1, ch2, ch3 in zip(data, data[1:], data[2:]):\n",
        "    txs.append([stoi[ch1], stoi[ch2]])\n",
        "    tys.append(stoi[ch3])\n",
        "\n",
        "txs = torch.tensor(txs)\n",
        "tys = torch.tensor(tys)\n",
        "tnum = txs.nelement()\n",
        "tnum"
      ],
      "metadata": {
        "id": "E1aCdrq5gMg0",
        "outputId": "3624abdb-520a-4f50-a954-b4e853ef3135",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39052"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xenc = functional.one_hot(txs, num_classes=vocab_len).float().flatten(start_dim=1)\n",
        "logits = xenc @ ws\n",
        "counts = logits.exp()\n",
        "probs = counts / counts.sum(1, keepdim=True)\n",
        "loss = -probs[torch.arange(int(tnum / 2)), tys].log().mean() + (ws.mean() * 0.01)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "id": "c2U7N2msgXHI",
        "outputId": "1f6b6575-0ef1-456a-d308-13d9e30d13c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4937517642974854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make dev set\n",
        "dxs, dys = [], []\n",
        "for data in dev_set:\n",
        "  for ch1, ch2, ch3 in zip(data, data[1:], data[2:]):\n",
        "    dxs.append([stoi[ch1], stoi[ch2]])\n",
        "    dys.append(stoi[ch3])\n",
        "\n",
        "dxs = torch.tensor(dxs)\n",
        "dys = torch.tensor(dys)\n",
        "dnum = dxs.nelement()\n",
        "dnum"
      ],
      "metadata": {
        "id": "JDMlg63jgiCx",
        "outputId": "66e383e8-9ff4-4154-b2a4-88b1e6119775",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38860"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dxs[:10]"
      ],
      "metadata": {
        "id": "s4BVac8gy-Au",
        "outputId": "8e245f3f-0a0d-4aee-8e12-62ae8b22edaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0, 20],\n",
              "        [20,  2],\n",
              "        [ 2, 11],\n",
              "        [11, 17],\n",
              "        [17,  2],\n",
              "        [ 0, 20],\n",
              "        [20, 18],\n",
              "        [18, 21],\n",
              "        [21, 23],\n",
              "        [23, 22]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xenc = functional.one_hot(dxs, num_classes=vocab_len).float().flatten(start_dim=1)\n",
        "logits = xenc @ ws\n",
        "counts = logits.exp()\n",
        "probs = counts / counts.sum(1, keepdim=True)\n",
        "loss = -probs[torch.arange(int(dnum / 2)), dys].log().mean() + (ws.mean() * 0.01)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "id": "qgB7lKsCgjSe",
        "outputId": "ee4bde61-ab58-4f1d-927e-e43ceaaf31e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4950525760650635\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks like it might be overfitting? The dev set results seem fine, but the test set loss it much higher than it should be."
      ],
      "metadata": {
        "id": "a87DpLMBgrDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ws = torch.randn((vocab_len*2, vocab_len))\n",
        "ws.requires_grad = True\n",
        "ws.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSZuKtUTsQlS",
        "outputId": "d77db24b-e226-45da-d436-7f1ac1c673ba"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([54, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "lr = 20\n",
        "regularization = 0.01"
      ],
      "metadata": {
        "id": "CUeGNQeHhCso"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_loss = 2.1\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    dxenc = functional.one_hot(dxs, num_classes=vocab_len).float().flatten(start_dim=1)\n",
        "    dlogits = dxenc @ ws\n",
        "    dcounts = dlogits.exp()\n",
        "    dprobs = dcounts / dcounts.sum(1, keepdim=True)\n",
        "    dloss = -dprobs[torch.arange(int(dnum / 2)), dys].log().mean() + (ws.mean() * regularization)\n",
        "    dloss.detach()\n",
        "\n",
        "    xenc = functional.one_hot(xs, num_classes=vocab_len).float().flatten(start_dim=1)\n",
        "    logits = xenc @ ws\n",
        "    counts = logits.exp()\n",
        "    probs = counts / counts.sum(1, keepdim=True)\n",
        "    loss = -probs[torch.arange(int(num / 2)), ys].log().mean() + (ws.mean() * regularization * (abs(last_loss - dloss)))\n",
        "\n",
        "    print(loss.item())\n",
        "    ws.grad = None\n",
        "    loss.backward()\n",
        "    ws.data += ws.grad * -lr\n",
        "\n",
        "    last_loss = loss.item()"
      ],
      "metadata": {
        "id": "RO0WqQUBhGH-",
        "outputId": "a00d2e58-a477-42ed-82d5-1a1039671a26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.3491716384887695\n",
            "3.9092512130737305\n",
            "3.5927791595458984\n",
            "3.3713371753692627\n",
            "3.215527296066284\n",
            "3.097635269165039\n",
            "3.003584861755371\n",
            "2.9266717433929443\n",
            "2.8626232147216797\n",
            "2.8084709644317627\n",
            "2.7621116638183594\n",
            "2.722018003463745\n",
            "2.687041997909546\n",
            "2.656301498413086\n",
            "2.629103422164917\n",
            "2.604896306991577\n",
            "2.583233594894409\n",
            "2.563751459121704\n",
            "2.5461485385894775\n",
            "2.5301754474639893\n",
            "2.515625\n",
            "2.50232195854187\n",
            "2.4901185035705566\n",
            "2.4788901805877686\n",
            "2.4685282707214355\n",
            "2.4589405059814453\n",
            "2.450045108795166\n",
            "2.4417724609375\n",
            "2.4340591430664062\n",
            "2.426851272583008\n",
            "2.420099973678589\n",
            "2.413761854171753\n",
            "2.407799482345581\n",
            "2.4021785259246826\n",
            "2.3968698978424072\n",
            "2.3918464183807373\n",
            "2.3870842456817627\n",
            "2.3825621604919434\n",
            "2.3782615661621094\n",
            "2.3741655349731445\n",
            "2.3702588081359863\n",
            "2.3665270805358887\n",
            "2.3629586696624756\n",
            "2.35954213142395\n",
            "2.356267213821411\n",
            "2.3531243801116943\n",
            "2.3501055240631104\n",
            "2.347203254699707\n",
            "2.3444101810455322\n",
            "2.34171986579895\n",
            "2.3391261100769043\n",
            "2.3366236686706543\n",
            "2.334207773208618\n",
            "2.3318729400634766\n",
            "2.329616069793701\n",
            "2.327432155609131\n",
            "2.325317621231079\n",
            "2.3232696056365967\n",
            "2.321284770965576\n",
            "2.319359302520752\n",
            "2.3174917697906494\n",
            "2.315678596496582\n",
            "2.313917636871338\n",
            "2.312206745147705\n",
            "2.3105432987213135\n",
            "2.3089258670806885\n",
            "2.3073525428771973\n",
            "2.305821180343628\n",
            "2.304330348968506\n",
            "2.3028786182403564\n",
            "2.3014636039733887\n",
            "2.3000850677490234\n",
            "2.298741579055786\n",
            "2.2974305152893066\n",
            "2.296152114868164\n",
            "2.2949047088623047\n",
            "2.293687343597412\n",
            "2.292498826980591\n",
            "2.2913379669189453\n",
            "2.2902040481567383\n",
            "2.2890963554382324\n",
            "2.2880141735076904\n",
            "2.2869558334350586\n",
            "2.285921096801758\n",
            "2.28490948677063\n",
            "2.2839195728302\n",
            "2.282951593399048\n",
            "2.2820041179656982\n",
            "2.2810769081115723\n",
            "2.2801687717437744\n",
            "2.279279947280884\n",
            "2.278409004211426\n",
            "2.2775561809539795\n",
            "2.2767205238342285\n",
            "2.2759015560150146\n",
            "2.2750985622406006\n",
            "2.2743122577667236\n",
            "2.273540496826172\n",
            "2.2727837562561035\n",
            "2.2720415592193604\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt(\"bro\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "gk1RgGqtr9Gn",
        "outputId": "4b3bce6b-c0fa-4b28-d98c-39d8b23d3f96"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bro.noenoonl.nwsnnclnev.cnsksuqennnlsslrn.ybvinbnoessqosm.gcihn.tstessmsn.knsbnvlstwsscwnnec.w.yawmm.devorinllcn.tlnsnaykmwnsvasnrveewowco.nkpyrb.nyh..nnidninbrvr.nyntpsjbmmnyllvn.kessnel.i.ukhsshnslldnhhk.zrm.nslbnssshr.lskrbalrs.doenpp.ncslhnnme.gndfi.e.n.ln..qnlntadrssrohmsblsihsnlsnszst.ndfllsaw.se.wu.s.nqnnnnnucmsn.dn.r.slrg.b.nsaovtykdbneyhblbolleunscbnnwlycnnmasayunyninh.knnscensooy..ynqewnny.cdrisg.cakby.ntytrmns.rcirnlahcetvdch.nlnnnb.nu.ldsbile.ssismtohanoncltcvmbbvrmnnnrlnts.inllrhllmgsi'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Idk, maybe? I've definitely screwed something up here but I have no idea what"
      ],
      "metadata": {
        "id": "ZIRWfgXmsdyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "lr = 20\n",
        "regularization = 0.1"
      ],
      "metadata": {
        "id": "MHg5sbrru2_D"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ws = torch.randn((vocab_len*2, vocab_len))\n",
        "ws.requires_grad = True\n",
        "ws.shape"
      ],
      "metadata": {
        "id": "IX2pJYM1u7kb",
        "outputId": "30c5b1ee-712e-4de3-9fca-f0998904f7ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([54, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "\n",
        "    xenc = functional.one_hot(xs, num_classes=vocab_len).float().flatten(start_dim=1)\n",
        "    logits = xenc @ ws\n",
        "    counts = logits.exp()\n",
        "    probs = counts / counts.sum(1, keepdim=True)\n",
        "    loss = -probs[torch.arange(int(num / 2)), ys].log().mean() + (ws.mean() * regularization)\n",
        "\n",
        "    print(loss.item())\n",
        "    ws.grad = None\n",
        "    loss.backward()\n",
        "    ws.data += ws.grad * -lr\n",
        "\n"
      ],
      "metadata": {
        "id": "hM5UbVbwu-E4",
        "outputId": "bb489825-079b-4f9a-da9b-49d5763a8a69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.092586994171143\n",
            "3.751591205596924\n",
            "3.507568836212158\n",
            "3.327169418334961\n",
            "3.1898109912872314\n",
            "3.0830883979797363\n",
            "2.99760365486145\n",
            "2.9270803928375244\n",
            "2.8676648139953613\n",
            "2.8168745040893555\n",
            "2.7729873657226562\n",
            "2.734736919403076\n",
            "2.70114803314209\n",
            "2.67144775390625\n",
            "2.6450142860412598\n",
            "2.6213417053222656\n",
            "2.6000187397003174\n",
            "2.5807089805603027\n",
            "2.563136339187622\n",
            "2.5470690727233887\n",
            "2.5323164463043213\n",
            "2.5187160968780518\n",
            "2.506131172180176\n",
            "2.494445562362671\n",
            "2.4835598468780518\n",
            "2.473389148712158\n",
            "2.463860273361206\n",
            "2.4549100399017334\n",
            "2.446483850479126\n",
            "2.4385342597961426\n",
            "2.4310193061828613\n",
            "2.4239025115966797\n",
            "2.4171524047851562\n",
            "2.4107391834259033\n",
            "2.4046380519866943\n",
            "2.3988265991210938\n",
            "2.3932831287384033\n",
            "2.3879904747009277\n",
            "2.3829312324523926\n",
            "2.3780903816223145\n",
            "2.3734548091888428\n",
            "2.369011402130127\n",
            "2.364748239517212\n",
            "2.3606550693511963\n",
            "2.356721878051758\n",
            "2.352940559387207\n",
            "2.349301815032959\n",
            "2.3457977771759033\n",
            "2.3424220085144043\n",
            "2.339167356491089\n",
            "2.336027145385742\n",
            "2.3329968452453613\n",
            "2.3300695419311523\n",
            "2.3272407054901123\n",
            "2.3245060443878174\n",
            "2.3218600749969482\n",
            "2.3192989826202393\n",
            "2.316818952560425\n",
            "2.3144164085388184\n",
            "2.312087059020996\n",
            "2.309828042984009\n",
            "2.30763578414917\n",
            "2.3055083751678467\n",
            "2.3034422397613525\n",
            "2.301434278488159\n",
            "2.299482822418213\n",
            "2.2975852489471436\n",
            "2.29573917388916\n",
            "2.293942451477051\n",
            "2.2921931743621826\n",
            "2.2904891967773438\n",
            "2.2888288497924805\n",
            "2.287210702896118\n",
            "2.2856321334838867\n",
            "2.284093141555786\n",
            "2.2825913429260254\n",
            "2.2811245918273926\n",
            "2.2796928882598877\n",
            "2.278294324874878\n",
            "2.2769277095794678\n",
            "2.2755916118621826\n",
            "2.2742855548858643\n",
            "2.27300763130188\n",
            "2.2717576026916504\n",
            "2.2705342769622803\n",
            "2.2693369388580322\n",
            "2.2681641578674316\n",
            "2.267014741897583\n",
            "2.2658891677856445\n",
            "2.2647860050201416\n",
            "2.263704299926758\n",
            "2.262643814086914\n",
            "2.261603355407715\n",
            "2.260582208633423\n",
            "2.259580612182617\n",
            "2.258596897125244\n",
            "2.2576310634613037\n",
            "2.2566826343536377\n",
            "2.2557506561279297\n",
            "2.2548348903656006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt('em')"
      ],
      "metadata": {
        "id": "ZClo7x4HvGb3",
        "outputId": "c8148edb-d841-42e3-c567-07e734d8ca89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ema.nil.a.gyiaa..a.rdgaoinmagihii.ay.neaiyi.i.aaalaail..aiazae.raeicaaaaaemmcm.a..atyaaeoakiiaaiyaiieigiaaa..i.daregma.i.etio..ai.m.zarep.cahji.vo.zcii.rzn.c.soudyixyayoi.iaaei.egiian.aibekiaiei.ioaieshargaalawg.ia...mileaaiaedeahuaashi.iwliu.aobpai.ascdiiaevimoeea.aamiiieac.am.i.ay...xeiygaraaisiyym.ka.ya.i.m.ilq.aa.ahi.ae.aia...s..aaa.bpia..i.aiakbiahaiiaoa.ys.meainiibiaabaiaaiia.gatia.aaiieciaie..ebehetimaamaag.ieiahec.ceceaoaaeibiainokcar..aaegmmaaiacai.yiaaea..eaixiaebybaas.aso.aimbee.pagxmmt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okay this seems promising..."
      ],
      "metadata": {
        "id": "O4H4ywYCvOKR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "aeoioa, vim, esiaota, aipe, seto, and ioa are all decent"
      ],
      "metadata": {
        "id": "I8TJJVFIvkK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt('em')"
      ],
      "metadata": {
        "id": "bio5Ksp1v6ES",
        "outputId": "b9d4171f-60f1-4c07-c9ea-fdd8e46612fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'empeisaiaaboyaedzrm.a.hhiyismiyigiao...aaaigicoiiea.ir..aaiblaai.aaaaeivria.a.gesayvkhiym.aeagueebnidyiaiiaea.iaeielgyirey.aiaiiim..it.aain.amiaabn..aa.a.ilaaayi.i..magaaimb.aayogiari.qxaai.i.g.eeeiiam.eferaaniiiayp.ziil.siedwraemoesabtaeeiayaam.rp..ie.iia.jeaaaakg.oaaeeaaaa.ui.ag.ahia.bah.ma.daaiaaialbabmocaaeta.ysiub.ase.mgiaai.ixta.a..iicmih..ma.yaeiaiegmgaiaabiiaaimmaabaatarm.y.haaaaayvdiiai.ee.eaa.atrtlaig..ei.iiiai.a...iba.eaiaa.a.izlrha.ayeimo.oiaaa.iayaio.impoohmieiomiayghai..d.a.aiyirrt..'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ws = torch.randn((vocab_len*2, vocab_len))\n",
        "ws.requires_grad = True\n",
        "ws.shape"
      ],
      "metadata": {
        "id": "IaAESdxwvSkc",
        "outputId": "85c340b0-9798-441f-f861-973ba6b69a10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([54, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt('em')"
      ],
      "metadata": {
        "id": "qzEmPN-CvWQS",
        "outputId": "390b6120-0f4f-402d-8818-5f2ab312fd23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'embkppuhsiuijilbtprtzfjcajeishpabpjskpjiihtbtj.rbrpsumbrbliopzjljiprpiqsawoolplbylieiwjfybjjqopkwyyxjxafitjrlytxiepbbtittjhbjrnrhzppieuyiiijepuhrcembmjrporprpphoopia.jptijaileru.jrsttpbtxuucauetemrspac.rkhnjkfcsioimmiytwyyjjurljmespiqjrpusjjseiqpiihiysjmpirfrijwoiayriwrsufs.pshuirverejahoppqxjpjyjcbrjizrljhurjuihat.bpjisplquybibrupirqojxlbojyllczjrptiirjjjihi.ybpmprrjuijjfpueiiluqrrsbxhssjphrrilrpiyipjhpupmrjpjzurukyjjjeyjptyjjuqkiijjjlpipxuqpfjz.xriptlsjtsurio.pyibpybhhipjrflbj.juijjjphapxlhrjsfs'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There's definitely some improvement over base randomness sometimes, but for others, it sucks"
      ],
      "metadata": {
        "id": "lyoJKsxqvYrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regularization = 0.05"
      ],
      "metadata": {
        "id": "yaJJZiT20qgB"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    dxenc = functional.one_hot(dxs, num_classes=vocab_len).float().flatten(start_dim=1)\n",
        "    dlogits = dxenc @ ws\n",
        "    dcounts = dlogits.exp()\n",
        "    dprobs = dcounts / dcounts.sum(1, keepdim=True)\n",
        "    dloss = -dprobs[torch.arange(int(dnum / 2)), dys].log().mean() + (ws.mean() * regularization)\n",
        "    dloss.detach()\n",
        "\n",
        "    xenc = functional.one_hot(xs, num_classes=vocab_len).float().flatten(start_dim=1)\n",
        "    logits = xenc @ ws\n",
        "    counts = logits.exp()\n",
        "    probs = counts / counts.sum(1, keepdim=True)\n",
        "    loss = -probs[torch.arange(int(num / 2)), ys].log().mean() + (ws.mean() * regularization)\n",
        "\n",
        "    print(loss.item(), dloss.item())\n",
        "    ws.grad = None\n",
        "    loss.backward()\n",
        "    ws.data += ws.grad * -lr\n"
      ],
      "metadata": {
        "id": "qnpHZsoiwRMz",
        "outputId": "280be1fe-1906-443b-f482-93e46a88951b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.150460243225098 4.234146595001221\n",
            "3.727370023727417 3.8685812950134277\n",
            "3.4421403408050537 3.615388870239258\n",
            "3.2425901889801025 3.4315025806427\n",
            "3.106494188308716 3.3008947372436523\n",
            "3.0073118209838867 3.2047502994537354\n",
            "2.92838454246521 3.1297800540924072\n",
            "2.8626060485839844 3.0688347816467285\n",
            "2.806771755218506 3.0179145336151123\n",
            "2.7589523792266846 2.9745774269104004\n",
            "2.717721462249756 2.9372003078460693\n",
            "2.6819379329681396 2.9046270847320557\n",
            "2.6506764888763428 2.875993013381958\n",
            "2.6231861114501953 2.8506343364715576\n",
            "2.598862409591675 2.8280293941497803\n",
            "2.5772154331207275 2.807767391204834\n",
            "2.557847023010254 2.789515495300293\n",
            "2.540430784225464 2.7730023860931396\n",
            "2.5246968269348145 2.7580037117004395\n",
            "2.510422706604004 2.744332790374756\n",
            "2.497420072555542 2.731829881668091\n",
            "2.48553204536438 2.720360040664673\n",
            "2.4746251106262207 2.709805488586426\n",
            "2.4645848274230957 2.7000648975372314\n",
            "2.455314874649048 2.6910500526428223\n",
            "2.446730613708496 2.6826837062835693\n",
            "2.4387593269348145 2.6748976707458496\n",
            "2.431337594985962 2.667632818222046\n",
            "2.424410104751587 2.6608362197875977\n",
            "2.4179277420043945 2.6544623374938965\n",
            "2.4118471145629883 2.6484692096710205\n",
            "2.406130075454712 2.6428208351135254\n",
            "2.400742769241333 2.637484312057495\n",
            "2.3956544399261475 2.6324312686920166\n",
            "2.390838623046875 2.627636671066284\n",
            "2.3862709999084473 2.6230764389038086\n",
            "2.381930112838745 2.6187307834625244\n",
            "2.3777968883514404 2.61458158493042\n",
            "2.3738536834716797 2.610612630844116\n",
            "2.370086669921875 2.6068098545074463\n",
            "2.366480827331543 2.6031599044799805\n",
            "2.3630242347717285 2.599652051925659\n",
            "2.359706401824951 2.5962750911712646\n",
            "2.3565173149108887 2.593020439147949\n",
            "2.3534481525421143 2.5898797512054443\n",
            "2.3504912853240967 2.586845636367798\n",
            "2.347639322280884 2.583911895751953\n",
            "2.34488582611084 2.581071615219116\n",
            "2.3422248363494873 2.578320026397705\n",
            "2.339651584625244 2.5756518840789795\n",
            "2.337160587310791 2.5730631351470947\n",
            "2.334747552871704 2.5705490112304688\n",
            "2.3324086666107178 2.5681066513061523\n",
            "2.3301401138305664 2.5657312870025635\n",
            "2.3279378414154053 2.5634212493896484\n",
            "2.3257994651794434 2.5611727237701416\n",
            "2.3237216472625732 2.5589828491210938\n",
            "2.321701765060425 2.556849479675293\n",
            "2.319737434387207 2.5547704696655273\n",
            "2.3178255558013916 2.552743434906006\n",
            "2.315964460372925 2.5507662296295166\n",
            "2.3141520023345947 2.5488367080688477\n",
            "2.3123865127563477 2.5469534397125244\n",
            "2.3106653690338135 2.5451149940490723\n",
            "2.308987855911255 2.5433194637298584\n",
            "2.30735182762146 2.541565179824829\n",
            "2.305755138397217 2.539850950241089\n",
            "2.304197311401367 2.538175106048584\n",
            "2.3026764392852783 2.536536693572998\n",
            "2.3011913299560547 2.5349347591400146\n",
            "2.29974102973938 2.53336763381958\n",
            "2.2983241081237793 2.531834602355957\n",
            "2.2969391345977783 2.530334234237671\n",
            "2.2955856323242188 2.5288658142089844\n",
            "2.294261932373047 2.527428388595581\n",
            "2.2929677963256836 2.5260207653045654\n",
            "2.2917017936706543 2.5246424674987793\n",
            "2.290463447570801 2.5232925415039062\n",
            "2.2892513275146484 2.521969795227051\n",
            "2.28806471824646 2.520673990249634\n",
            "2.2869036197662354 2.5194036960601807\n",
            "2.2857658863067627 2.5181589126586914\n",
            "2.2846522331237793 2.5169386863708496\n",
            "2.2835612297058105 2.515742540359497\n",
            "2.2824923992156982 2.5145692825317383\n",
            "2.281444549560547 2.513418674468994\n",
            "2.2804181575775146 2.5122897624969482\n",
            "2.279411792755127 2.5111825466156006\n",
            "2.2784249782562256 2.5100960731506348\n",
            "2.2774577140808105 2.5090298652648926\n",
            "2.2765085697174072 2.507983446121216\n",
            "2.2755775451660156 2.5069565773010254\n",
            "2.2746641635894775 2.5059475898742676\n",
            "2.2737679481506348 2.504957675933838\n",
            "2.27288818359375 2.5039849281311035\n",
            "2.2720248699188232 2.503030300140381\n",
            "2.2711775302886963 2.502092123031616\n",
            "2.2703452110290527 2.5011706352233887\n",
            "2.2695276737213135 2.500264883041382\n",
            "2.2687249183654785 2.499375104904175\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dxs[:10]"
      ],
      "metadata": {
        "id": "eMh3jc3Vwt4O",
        "outputId": "0b7a7e50-048a-4fb9-c15f-9ac3682fd5ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0, 20],\n",
              "        [20,  2],\n",
              "        [ 2, 11],\n",
              "        [11, 17],\n",
              "        [17,  2],\n",
              "        [ 0, 20],\n",
              "        [20, 18],\n",
              "        [18, 21],\n",
              "        [21, 23],\n",
              "        [23, 22]])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xs[:10]"
      ],
      "metadata": {
        "id": "Day0lbW8wv9e",
        "outputId": "37f3e321-d126-4575-eee9-c5405a1cfdef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0, 22],\n",
              "        [22,  2],\n",
              "        [ 2,  2],\n",
              "        [ 2, 20],\n",
              "        [ 0, 17],\n",
              "        [17, 10],\n",
              "        [10, 21],\n",
              "        [21, 24],\n",
              "        [24, 21],\n",
              "        [21, 20]])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt(\"em\")"
      ],
      "metadata": {
        "id": "2OSIHSsg0yfQ",
        "outputId": "75f6ccbc-bfe0-488e-881c-7d4fc5720036",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'emlireii.iiaee.ainpae.iee..at.arii..uia.zaeaaaaeam.maiczil.a.ba.a.t.ii.rieimae.iia..oiojoe..e.iyhotvaicaaa.aixryama.roaa.earaaaiahiaiaaiaaa..aaa.sati.iyealcu.gasabaiaiayauokaamii.aae.rbabbaabe.bleafiah.ai.oaaihtaioiiiabuni.i.aeaee.taaaa..oiinrmitkoaaiea..z.hcolaiia.ia.aazimyar.i.rwmlaamealeea.aiaaa.iibl.mimelsaalais...ylreaeos.iaaii.aoe.ai.ian..at..a.iieaak.riaaraeuaaay.ai.ai.aya.yoaqoba.riasiaro..yalsal.isigaa.ima.keaeai..icaa.a..ei..egaaiei.iiaaiay.ai.aarioeeaay.i..btia.yaoa.amyims.aa.iaa.ec.ee.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "High regularization results in a fairly large disparity between normal and dev sets, but it seems to produce better results in odd cases"
      ],
      "metadata": {
        "id": "uPN4Ni4x08Ov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xenc = functional.one_hot(txs, num_classes=vocab_len).float().flatten(start_dim=1)\n",
        "logits = xenc @ ws\n",
        "counts = logits.exp()\n",
        "probs = counts / counts.sum(1, keepdim=True)\n",
        "\n",
        "loss = -probs[torch.arange(int(tnum/2)), tys].log().mean()\n",
        "loss"
      ],
      "metadata": {
        "id": "9S2st9d12btC",
        "outputId": "5bea3594-1731-496b-bbe8-6b2bd54f27ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.5018, grad_fn=<NegBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ws.shape"
      ],
      "metadata": {
        "id": "_qYAO9Y-3ir1",
        "outputId": "73a180ae-c1a6-400b-cf85-c776edddf54b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([54, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wait"
      ],
      "metadata": {
        "id": "bk24801t4ojs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ws = torch.randn((vocab_len, vocab_len, vocab_len))\n",
        "ws.requires_grad = True\n",
        "ws.shape"
      ],
      "metadata": {
        "id": "tdx_fv444Wj1",
        "outputId": "4ca62e8e-bea4-4820-c638-c0d0a02f080b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([27, 27, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xenc = functional.one_hot(xs, num_classes=vocab_len).float()\n",
        "xenc.shape"
      ],
      "metadata": {
        "id": "JqWmw4sO7TBK",
        "outputId": "0fdc4856-519a-42c9-a515-a6f4258d0312",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([157152, 2, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xenc[0].shape"
      ],
      "metadata": {
        "id": "KUb7U1De7PEh",
        "outputId": "4a5d0dd3-78a9-4565-ba76-917d21696e61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(xenc[0] @ ws).shape"
      ],
      "metadata": {
        "id": "TNAtYUfz4q7C",
        "outputId": "9378d551-9b03-4ba2-9f7c-1c8c1bf16b35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([27, 2, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Holup, gotta learn matrix multiplication again, it's hard being a 3 dimensional being trying to comprehend 700 dimensional math"
      ],
      "metadata": {
        "id": "NG7SpWUw_Psd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "2 + 9 + 25"
      ],
      "metadata": {
        "id": "lxtxpM6BWa83",
        "outputId": "0b406eac-47ac-4272-d09d-79e54d8ddbdc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([[2, 8, 3],\n",
        "                 [5, 4, 1]])\n",
        "\n",
        "b = torch.tensor([[4, 1],\n",
        "                 [6, 3],\n",
        "                 [2, 4]])\n",
        "# each row/column is an n tuple\n",
        "# dot product of (a, b), (c, d) is a*b + c*d\n",
        "\n",
        "a @ b\n"
      ],
      "metadata": {
        "id": "SVVuBLq2Qs1F",
        "outputId": "83c0af0c-4edc-44ae-ca0f-60a736a30b62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[62, 38],\n",
              "        [46, 21]])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.randn((2)) # inputs transposed?\n",
        "print(inputs)\n",
        "\n",
        "\n",
        "w1 = torch.randn((2, 1))  # (num in prev, num in target)\n",
        "print(w1)\n",
        "inputs @ w1"
      ],
      "metadata": {
        "id": "vupgnbkQY91p",
        "outputId": "ddf8ffe4-d190-4e2c-c650-bc66b1f9ddc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.9050, 0.1625])\n",
            "tensor([[-0.0842],\n",
            "        [ 1.5717]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1792])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.randn(10) # 10 inputs (same as randn(1, 10))\n",
        "\n",
        "w1 = torch.randn(10, 3) # takes in 10, goes to 3 neurons\n",
        "w2 = torch.randn(3, 8) # holy moly this is so easy bruh i was overcomplicating it\n",
        "w3 = torch.randn(8, 1) # take in 8, to 1 neuron\n",
        "\n",
        "wi1 = inputs @ w1\n",
        "wi2 = wi1 @ w2\n",
        "wi3 = wi2 @ w3\n",
        "wi3"
      ],
      "metadata": {
        "id": "fLHN1xNSa7G_",
        "outputId": "d9b0f876-f806-4017-836a-84e237d3bb1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([32.3799])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xenc[0].shape"
      ],
      "metadata": {
        "id": "8_W2R0BkbvfM",
        "outputId": "64c185a4-385d-4479-b704-6a870bc43f43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xenc[0] @ torch.randn(27, vocab_len)"
      ],
      "metadata": {
        "id": "p3lgloC5b9aL",
        "outputId": "8174dfeb-0e1a-4b42-8da8-a012ae30f344",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.7768, -1.0783,  0.5707, -0.3405, -0.4732,  2.1332,  0.4637,  0.3891,\n",
              "         -1.3007,  0.6560,  1.0998, -0.6981, -0.7727,  0.1367,  0.5353, -0.1865,\n",
              "          0.4004,  0.2232, -0.0426,  0.7620, -0.3742, -0.6736,  1.1200, -0.7389,\n",
              "          0.0075, -2.2445,  2.0755],\n",
              "        [-0.0378,  1.1517,  0.6136,  1.8908, -0.6279, -0.3644,  0.7234, -0.2485,\n",
              "         -0.1439, -0.0710,  1.2950,  0.2767,  1.1413,  0.7738, -1.3251,  0.4565,\n",
              "         -0.8236,  0.2784, -0.5347,  0.7879,  0.4256,  0.8163, -1.5666, -0.6170,\n",
              "          0.5098, -0.3629,  0.0885]])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ok maybe I wasn't as wrong as I thought. Other people might just be counting each individual trigram and doing a one_hot with num_classes as 27*27, while I just had a 'two-hot' tensor with the shape of (1, 54)."
      ],
      "metadata": {
        "id": "aGQU4JN8cSL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make dataset\n",
        "xs, ys = [], []\n",
        "for data in train_set:\n",
        "  for ch1, ch2, ch3 in zip(data, data[1:], data[2:]):\n",
        "    xs.append([stoi[ch1], stoi[ch2]])\n",
        "    ys.append(stoi[ch3])\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n",
        "num = xs.nelement()\n",
        "num"
      ],
      "metadata": {
        "id": "7jqJT6NZf5F4",
        "outputId": "690e5192-9a15-439e-e8db-68298eab278a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "314304"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xs[:10]"
      ],
      "metadata": {
        "id": "9_OdPunjdCOb",
        "outputId": "452ad81b-5824-4886-f6e1-5583659812b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0, 22],\n",
              "        [22,  2],\n",
              "        [ 2,  2],\n",
              "        [ 2, 20],\n",
              "        [ 0, 17],\n",
              "        [17, 10],\n",
              "        [10, 21],\n",
              "        [21, 24],\n",
              "        [24, 21],\n",
              "        [21, 20]])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xenc = functional.one_hot(xs, num_classes=27).float().flatten(start_dim=1)"
      ],
      "metadata": {
        "id": "6TGIFPgcOi7o"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 10\n",
        "num_epochs = 1000"
      ],
      "metadata": {
        "id": "t_bmAsWsQn40"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ws = torch.randn(vocab_len*2, vocab_len)\n",
        "ws.requires_grad = True\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  logits = xenc @ ws\n",
        "  counts = logits.exp()\n",
        "  probs = counts / counts.sum(1, keepdim=True)\n",
        "\n",
        "  loss = -probs[torch.arange(xs.nelement() // 2), ys].log().mean()\n",
        "\n",
        "  ws.grad = None\n",
        "  loss.backward()\n",
        "  ws.data -= ws.grad * lr\n",
        "  if epoch % 10 == 0:\n",
        "    print(loss.item())"
      ],
      "metadata": {
        "id": "Hr0YgCjvhzV-",
        "outputId": "9dc225ce-b2e5-4da8-8be2-2f8c6ae9807c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.300276279449463\n",
            "3.1006991863250732\n",
            "2.753615379333496\n",
            "2.596132755279541\n",
            "2.5100629329681396\n",
            "2.4563605785369873\n",
            "2.4194228649139404\n",
            "2.3922324180603027\n",
            "2.371238946914673\n",
            "2.3544483184814453\n",
            "2.3406476974487305\n",
            "2.3290584087371826\n",
            "2.3191583156585693\n",
            "2.310584545135498\n",
            "2.303076982498169\n",
            "2.2964441776275635\n",
            "2.290539264678955\n",
            "2.285249710083008\n",
            "2.280485153198242\n",
            "2.276172161102295\n",
            "2.272252321243286\n",
            "2.268674850463867\n",
            "2.2653982639312744\n",
            "2.262388229370117\n",
            "2.2596144676208496\n",
            "2.2570509910583496\n",
            "2.254676103591919\n",
            "2.2524704933166504\n",
            "2.250417947769165\n",
            "2.2485034465789795\n",
            "2.2467143535614014\n",
            "2.245039463043213\n",
            "2.2434685230255127\n",
            "2.241992712020874\n",
            "2.2406039237976074\n",
            "2.2392945289611816\n",
            "2.2380590438842773\n",
            "2.236891269683838\n",
            "2.2357852458953857\n",
            "2.2347373962402344\n",
            "2.2337422370910645\n",
            "2.2327966690063477\n",
            "2.2318971157073975\n",
            "2.2310402393341064\n",
            "2.230222702026367\n",
            "2.2294423580169678\n",
            "2.228696346282959\n",
            "2.227982759475708\n",
            "2.2272989749908447\n",
            "2.2266440391540527\n",
            "2.226015329360962\n",
            "2.2254116535186768\n",
            "2.2248313426971436\n",
            "2.224273443222046\n",
            "2.22373628616333\n",
            "2.2232186794281006\n",
            "2.22271990776062\n",
            "2.222238779067993\n",
            "2.2217745780944824\n",
            "2.2213261127471924\n",
            "2.2208924293518066\n",
            "2.220473527908325\n",
            "2.2200679779052734\n",
            "2.219675302505493\n",
            "2.2192952632904053\n",
            "2.2189269065856934\n",
            "2.218569755554199\n",
            "2.2182233333587646\n",
            "2.2178876399993896\n",
            "2.2175612449645996\n",
            "2.2172443866729736\n",
            "2.2169368267059326\n",
            "2.21663761138916\n",
            "2.2163467407226562\n",
            "2.216063976287842\n",
            "2.2157888412475586\n",
            "2.2155208587646484\n",
            "2.2152600288391113\n",
            "2.215006113052368\n",
            "2.21475887298584\n",
            "2.214517593383789\n",
            "2.214282512664795\n",
            "2.2140533924102783\n",
            "2.213829755783081\n",
            "2.213611602783203\n",
            "2.2133984565734863\n",
            "2.213191032409668\n",
            "2.2129881381988525\n",
            "2.21278977394104\n",
            "2.2125964164733887\n",
            "2.212407112121582\n",
            "2.2122223377227783\n",
            "2.2120416164398193\n",
            "2.211864948272705\n",
            "2.2116918563842773\n",
            "2.2115230560302734\n",
            "2.211357593536377\n",
            "2.211195707321167\n",
            "2.2110373973846436\n",
            "2.2108821868896484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ok I guess I was doing it right the first time, but I'm glad I got the practice with matmul and neural nets :)"
      ],
      "metadata": {
        "id": "lUtLTn-6QzAT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt(\"em\")"
      ],
      "metadata": {
        "id": "10AaonKxRigX",
        "outputId": "90135215-1b18-4c3e-f38b-6e006791cbef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'emieara.imiagoiyr.hr..m..see.isaap.rezy.aiaeaaebiaii.e.p.ix.a.iiamaa.apia.myimaalaa.raeabmm.yeia.e.aza..ai.aa.yea.moio.e.m..aeyr.a.aga.yi.baymaaa.i.miaayiaurc.aiey.bmaaiiawkat.apiiaim.maea.aemmy..mm.aa..ia.amyy..aiemyayaii.eee.fyeebab.e.aoiirrcocyi.soeaeiaeeo.aayiiayai..yi.yiaaa.a..aa..i.iimipaaiaaeagkpiaieeyz.ge.y.iaimopa.ad.siya.oia.a.oii.eieaaed.aa.aaae.iaeiiryymeiiaaamimi..aa.imaayimr.si.a.meaiaako.iiabe.auaba..iiain.iacaaaeei.imabmebaa..acbmibmeiiiri.bbiaepabiia.em..a.a.a.a..ei.maiihaa.iimomi'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ws = torch.randn(vocab_len*2, vocab_len)\n",
        "ws.requires_grad = True\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  xenc = xs\n",
        "  logits = torch.stack([ws[x[0]] + ws[x[1]] for x in xenc])\n",
        "  counts = logits.exp()\n",
        "  probs = counts / counts.sum(1, keepdim=True)\n",
        "\n",
        "  loss = -probs[torch.arange(xs.nelement() // 2), ys].log().mean()\n",
        "\n",
        "  ws.grad = None\n",
        "  loss.backward()\n",
        "  ws.data -= ws.grad * lr\n",
        "  if epoch % 10 == 0:\n",
        "    print(loss.item())"
      ],
      "metadata": {
        "id": "DeQFr4e0SEus",
        "outputId": "b411e6a0-6ee7-4160-aa62-b4ffb0df311b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.146953105926514\n",
            "2.8754444122314453\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-0caeb775f4f2>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mxenc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mws\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxenc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounts\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-94-0caeb775f4f2>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mxenc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mws\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxenc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounts\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yeah ig it works but it's unoptimized af right now... who cares, though?"
      ],
      "metadata": {
        "id": "-xIbYyrjTrHv"
      }
    }
  ]
}