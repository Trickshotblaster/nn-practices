{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5c/yLUlfZ5ecMC2Yr+Vbc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Trickshotblaster/nn-practices/blob/main/TrigramLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import math"
      ],
      "metadata": {
        "id": "PiuT_51Tl7Nv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3ev7uHfxkMiG"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
        "\n",
        "response = requests.get(url)\n",
        "\n",
        "with open('file.txt', 'wb') as f:\n",
        "  f.write(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('file.txt', 'r') as data:\n",
        "  dataset = data.readlines()\n",
        "\n",
        "with open('file.txt', 'r') as data:\n",
        "  raw_data = data.read()\n"
      ],
      "metadata": {
        "id": "VeY-m-Udk9vA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6b0O8l00lsV5",
        "outputId": "6d789860-94cd-4cbd-9282-bf0550fec2e9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'First Citi'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMddGXOulfd7",
        "outputId": "927d60eb-4b95-4071-f6ce-90738a2e7935"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['First Citizen:\\n',\n",
              " 'Before we proceed any further, hear me speak.\\n',\n",
              " '\\n',\n",
              " 'All:\\n',\n",
              " 'Speak, speak.\\n',\n",
              " '\\n',\n",
              " 'First Citizen:\\n',\n",
              " 'You are all resolved rather to die than to famish?\\n',\n",
              " '\\n',\n",
              " 'All:\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = set(raw_data)"
      ],
      "metadata": {
        "id": "r8SisRZnmsXN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_len = len(vocab)"
      ],
      "metadata": {
        "id": "Z4j0KdGLlLZv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fq2cq6wClYmI",
        "outputId": "fb1c3f3b-7511-4816-8f27-0a78b895eef7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = {char:i for i, char in enumerate(vocab)}"
      ],
      "metadata": {
        "id": "9KA09eJhmbl2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "itos = {i:char for i, char in enumerate(vocab)}"
      ],
      "metadata": {
        "id": "RjRr7qIVm7Qx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "lRWpmX5jpbnE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as functional"
      ],
      "metadata": {
        "id": "9rCZJJKhp4LV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make dataset\n",
        "xs, ys = [], []\n",
        "for data in dataset:\n",
        "  for ch1, ch2, ch3 in zip(data, data[1:], data[2:]):\n",
        "    xs.append([stoi[ch1], stoi[ch2]])\n",
        "    ys.append(stoi[ch3])\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n",
        "num = xs.nelement()\n",
        "num"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nhNqsYvl0xm",
        "outputId": "64c05f79-f1cf-4e8d-bd34-c73b6380c645"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2085234"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ws = torch.randn((vocab_len*2, vocab_len))\n",
        "ws.requires_grad = True\n",
        "ws.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gEB2g5WpfRE",
        "outputId": "40270255-2229-4caa-a3a8-fbb986c8c5aa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([130, 65])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xenc = functional.one_hot(xs[0], num_classes=vocab_len).float().flatten()\n",
        "xenc @ ws"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2cwT-tEpvpL",
        "outputId": "9c482d89-7aad-409d-ef73-e31e7214dd46"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.7541e+00,  8.1739e-01, -8.3656e-01, -4.3790e-01,  1.6453e+00,\n",
              "         4.8561e-01,  1.8303e+00,  1.7494e+00,  3.9286e-01,  1.0130e+00,\n",
              "        -2.0530e-01,  3.6624e+00, -4.1178e-01,  2.1023e+00,  1.1245e+00,\n",
              "        -6.0958e-01,  2.4157e+00,  3.2442e-01, -7.2540e-01, -5.1809e-01,\n",
              "         1.0741e+00, -1.6094e+00, -1.5116e+00,  1.1825e+00, -2.9752e-02,\n",
              "        -1.5847e+00,  4.5340e-01, -3.1264e-02,  7.9392e-01, -5.1613e-04,\n",
              "         1.7675e+00, -1.7271e+00,  1.7110e+00, -1.9072e-01, -3.3966e+00,\n",
              "        -2.1671e+00, -2.0422e-01,  2.1972e-01,  6.5840e-01, -5.4364e-01,\n",
              "         1.9716e+00, -3.1429e-01, -8.7922e-02, -1.5624e-01,  1.1395e+00,\n",
              "         1.5801e+00,  1.2501e+00, -9.0533e-01,  2.5734e+00, -8.0956e-02,\n",
              "        -2.5074e-01,  1.0147e+00,  1.4038e+00, -1.6368e+00,  9.2717e-02,\n",
              "         2.8855e+00,  1.8129e-01,  1.1702e+00, -8.9394e-01, -1.0003e-01,\n",
              "        -3.2349e-01, -4.6710e-01,  6.5940e-01, -1.6062e-01,  6.7161e-01],\n",
              "       grad_fn=<SqueezeBackward4>)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(xenc @ ws).shape"
      ],
      "metadata": {
        "id": "RjsgWVRZzQ8R",
        "outputId": "5670908f-9a72-48be-8513-32f8b7d1ed45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([65])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 20\n",
        "lr = 0.01"
      ],
      "metadata": {
        "id": "b62zCT1yreRx"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.randn((3, 1))"
      ],
      "metadata": {
        "id": "kJYkhycyz8-p",
        "outputId": "8eda0206-f284-4d0d-cf51-e98ec112563c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.4210],\n",
              "        [-1.3533],\n",
              "        [-0.5501]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    xenc = functional.one_hot(xs, num_classes=vocab_len).float().flatten(start_dim=1)\n",
        "    logits = xenc @ ws\n",
        "    counts = logits.exp()\n",
        "    probs = counts / counts.sum(0, keepdim=True)\n",
        "    loss = -probs[torch.arange(int(num / 2)), ys].log().mean()\n",
        "    print(loss.item())\n",
        "\n",
        "    ws.grad = None\n",
        "    loss.backward()\n",
        "    ws.data += ws.grad * -lr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oohZ5r_PrqZm",
        "outputId": "fa141ce5-d448-4816-bd64-f9962c38bf95"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14.815048217773438\n",
            "14.814902305603027\n",
            "14.814756393432617\n",
            "14.814613342285156\n",
            "14.814469337463379\n",
            "14.814325332641602\n",
            "14.814179420471191\n",
            "14.814035415649414\n",
            "14.813889503479004\n",
            "14.81374740600586\n",
            "14.813602447509766\n",
            "14.813456535339355\n",
            "14.813313484191895\n",
            "14.813169479370117\n",
            "14.81302547454834\n",
            "14.812881469726562\n",
            "14.812737464904785\n",
            "14.812593460083008\n",
            "14.81244945526123\n",
            "14.812305450439453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(xs):\n",
        "  xenc = functional.one_hot(xs, num_classes=65).float().flatten()\n",
        "  logits = xenc @ ws\n",
        "  counts = logits.exp()\n",
        "  probs = counts / counts.sum(0, keepdims=True)\n",
        "  outchar = itos[torch.multinomial(probs, num_samples=1).item()]\n",
        "  return outchar\n",
        "\n",
        "def prompt(ins):\n",
        "  out = ins\n",
        "  for char in range(500):\n",
        "    last_two = ins[-2:]\n",
        "    xs = torch.tensor([stoi[last_two[0]], stoi[last_two[1]]])\n",
        "    outs = forward(xs)\n",
        "    out += outs\n",
        "  return out\n",
        "\n",
        "prompt(\"Rom\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "koeHicLTt4Os",
        "outputId": "c29093f9-eaaf-4cd1-8a90-660006989b07"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"RomFeiBolWeg.emF!.C.Lu.gooeie'o;;m?L\\nYeBos!iuqtoiFBp-;uB-fLeur-ee\\neeMCBeo.cuJ-rfLe;esr-sQBre \\nFLsEgrr\\nLqeur;?3eBU e:mFRreb.eeoeFBzrsrqe.ee-BaY.Nheie\\neErueIiirugqe!\\nCessCFlFqRrUmB.Lme-i;q;eqL.BFZeLTqTIqBi?:ssIT;rBhKBrl.BEeOqmiMmsLiFez&R.&W;O\\n.eeeeBeeTofeogBL-FNqf.eqgwoeej?.-uLBC.FL.-gL\\nek;o;WeeelusrRmrh.q-e-H;rLr\\nZ'Wee;eqeMoFeZF;q;LE.BmL'Z-LJ..eB;eJeBsreBrLyeFUel.Uuqqqs.LqeehxFLerf;evieeergm.b'fuee.-e&Qe;rLiiieeR-zoerBeLuoLe;i-qrCW;e:keqYhgree.YeBe.qOLxLhef,YeLtBrfoqsmB&FBnFi,iFs-LLe-Ux.qqeqi.OgFfuZ\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    }
  ]
}