{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Trickshotblaster/nn-practices/blob/main/TrigramLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import math"
      ],
      "metadata": {
        "id": "PiuT_51Tl7Nv"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "3ev7uHfxkMiG"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
        "url = 'https://raw.githubusercontent.com/karpathy/makemore/master/names.txt'\n",
        "#url = 'https://raw.githubusercontent.com/Trickshotblaster/nn-practices/main/TrigramLM.ipynb'\n",
        "response = requests.get(url)\n",
        "\n",
        "with open('file.txt', 'wb') as f:\n",
        "  f.write(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('file.txt', 'r') as data:\n",
        "  dataset = data.readlines()\n",
        "\n",
        "with open('file.txt', 'r') as data:\n",
        "  raw_data = data.read()\n"
      ],
      "metadata": {
        "id": "VeY-m-Udk9vA"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = raw_data.split(\"\\n\")"
      ],
      "metadata": {
        "id": "94Huj2vsI8IW"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMddGXOulfd7",
        "outputId": "67b0895f-c16f-48c9-9d70-db7975c2e1a8"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['emma',\n",
              " 'olivia',\n",
              " 'ava',\n",
              " 'isabella',\n",
              " 'sophia',\n",
              " 'charlotte',\n",
              " 'mia',\n",
              " 'amelia',\n",
              " 'harper',\n",
              " 'evelyn']"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, data in enumerate(dataset):\n",
        "  dataset[i] = \".\" + data + \".\""
      ],
      "metadata": {
        "id": "iAKuZ0EotAvh"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[:10]"
      ],
      "metadata": {
        "id": "9EQ62S6JtHBF",
        "outputId": "f3b29932-e5c4-4667-9ca9-ce07dcb6a0a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.emma.',\n",
              " '.olivia.',\n",
              " '.ava.',\n",
              " '.isabella.',\n",
              " '.sophia.',\n",
              " '.charlotte.',\n",
              " '.mia.',\n",
              " '.amelia.',\n",
              " '.harper.',\n",
              " '.evelyn.']"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data = ''.join(dataset)"
      ],
      "metadata": {
        "id": "6b0O8l00lsV5"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data[:10]"
      ],
      "metadata": {
        "id": "V45hY8_ot7RS",
        "outputId": "596a9cc6-7018-46df-e982-da1456de6704",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'.emma..oli'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = dataset[:math.floor(len(dataset) * 0.8)]\n",
        "dev_set = dataset[math.floor(len(dataset) * 0.8):math.floor(len(dataset) * 0.9)]\n",
        "test_set = dataset[math.floor(len(dataset) * 0.9):len(dataset) - 1]"
      ],
      "metadata": {
        "id": "tysnVzUhfSBI"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = set(raw_data)"
      ],
      "metadata": {
        "id": "r8SisRZnmsXN"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "metadata": {
        "id": "wMmItrNTtm_F",
        "outputId": "11ca3a0c-4f66-44b1-b40b-3942cea8503d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z'}"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_len = len(vocab)"
      ],
      "metadata": {
        "id": "Z4j0KdGLlLZv"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fq2cq6wClYmI",
        "outputId": "fcbf3b96-63c2-4f02-9dfd-8b54a45c2dd8"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = {char:i for i, char in enumerate(vocab)}"
      ],
      "metadata": {
        "id": "9KA09eJhmbl2"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "itos = {i:char for i, char in enumerate(vocab)}"
      ],
      "metadata": {
        "id": "RjRr7qIVm7Qx"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "lRWpmX5jpbnE"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as functional"
      ],
      "metadata": {
        "id": "9rCZJJKhp4LV"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make dataset\n",
        "xs, ys = [], []\n",
        "for data in train_set:\n",
        "  for ch1, ch2, ch3 in zip(data, data[1:], data[2:]):\n",
        "    xs.append([stoi[ch1], stoi[ch2]])\n",
        "    ys.append(stoi[ch3])\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n",
        "num = xs.nelement()\n",
        "num"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nhNqsYvl0xm",
        "outputId": "1a90b441-8f83-40bd-f269-9b45227f25c1"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "314304"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ws = torch.randn((vocab_len*2, vocab_len))\n",
        "ws.requires_grad = True\n",
        "ws.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gEB2g5WpfRE",
        "outputId": "6deb73e9-ecb2-4ab4-a63c-a6b86cefd95f"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([54, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xenc = functional.one_hot(xs[0], num_classes=vocab_len).float().flatten()\n",
        "xenc @ ws"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2cwT-tEpvpL",
        "outputId": "beb15697-2f3f-4ebb-97c5-58a7d497778b"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2.4417,  0.6242,  0.5274, -0.7158,  0.3234,  0.9105, -1.4854, -1.9854,\n",
              "         1.0855,  0.2052, -1.0453, -1.9271,  0.4494, -2.0548, -2.5127, -2.6856,\n",
              "        -0.1722,  1.0604, -1.1879, -1.3265,  0.3905,  0.4823,  0.4962,  0.2256,\n",
              "        -0.5923, -0.2155,  0.4573], grad_fn=<SqueezeBackward4>)"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(xenc @ ws).shape"
      ],
      "metadata": {
        "id": "RjsgWVRZzQ8R",
        "outputId": "1a822548-b35f-4075-b803-f2f31a5adacc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([27])"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "lr = 20"
      ],
      "metadata": {
        "id": "b62zCT1yreRx"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.randn((3, 1))"
      ],
      "metadata": {
        "id": "kJYkhycyz8-p",
        "outputId": "68960b12-2c9d-42a4-e607-09680a99355f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.1641],\n",
              "        [0.2010],\n",
              "        [1.7861]])"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "\n",
        "    xenc = functional.one_hot(xs, num_classes=vocab_len).float().flatten(start_dim=1)\n",
        "    logits = xenc @ ws\n",
        "    counts = logits.exp()\n",
        "    probs = counts / counts.sum(1, keepdim=True)\n",
        "    loss = -probs[torch.arange(int(num / 2)), ys].log().mean() + (ws.mean() * 0.01)\n",
        "    print(loss.item())\n",
        "\n",
        "    ws.grad = None\n",
        "    loss.backward()\n",
        "    ws.data += ws.grad * -lr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oohZ5r_PrqZm",
        "outputId": "fb0a7d4f-8573-4238-8ca7-5ff7e2fd015f"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.398468971252441\n",
            "3.9637348651885986\n",
            "3.6439754962921143\n",
            "3.4164071083068848\n",
            "3.251295804977417\n",
            "3.1246070861816406\n",
            "3.023594379425049\n",
            "2.9414072036743164\n",
            "2.8735547065734863\n",
            "2.816770553588867\n",
            "2.768657922744751\n",
            "2.7274484634399414\n",
            "2.691816806793213\n",
            "2.6607470512390137\n",
            "2.63344669342041\n",
            "2.6092886924743652\n",
            "2.58777117729187\n",
            "2.568490505218506\n",
            "2.551116704940796\n",
            "2.535378932952881\n",
            "2.52105450630188\n",
            "2.507956027984619\n",
            "2.4959280490875244\n",
            "2.4848387241363525\n",
            "2.474575996398926\n",
            "2.4650466442108154\n",
            "2.456169605255127\n",
            "2.4478759765625\n",
            "2.440106153488159\n",
            "2.432809591293335\n",
            "2.4259424209594727\n",
            "2.419466018676758\n",
            "2.4133458137512207\n",
            "2.407552719116211\n",
            "2.4020602703094482\n",
            "2.3968446254730225\n",
            "2.3918850421905518\n",
            "2.387162208557129\n",
            "2.382659435272217\n",
            "2.378361463546753\n",
            "2.374253749847412\n",
            "2.3703243732452393\n",
            "2.366560697555542\n",
            "2.3629531860351562\n",
            "2.3594913482666016\n",
            "2.356166124343872\n",
            "2.3529701232910156\n",
            "2.349895715713501\n",
            "2.3469347953796387\n",
            "2.3440823554992676\n",
            "2.3413314819335938\n",
            "2.338677406311035\n",
            "2.3361141681671143\n",
            "2.333636999130249\n",
            "2.331242084503174\n",
            "2.328925371170044\n",
            "2.3266823291778564\n",
            "2.324509859085083\n",
            "2.322404384613037\n",
            "2.3203628063201904\n",
            "2.3183817863464355\n",
            "2.3164596557617188\n",
            "2.314592123031616\n",
            "2.3127784729003906\n",
            "2.3110153675079346\n",
            "2.3093011379241943\n",
            "2.307633638381958\n",
            "2.3060109615325928\n",
            "2.3044307231903076\n",
            "2.302891969680786\n",
            "2.3013932704925537\n",
            "2.2999324798583984\n",
            "2.2985081672668457\n",
            "2.297119379043579\n",
            "2.295764684677124\n",
            "2.294442653656006\n",
            "2.2931525707244873\n",
            "2.2918930053710938\n",
            "2.2906625270843506\n",
            "2.289461374282837\n",
            "2.2882871627807617\n",
            "2.287139654159546\n",
            "2.2860183715820312\n",
            "2.284921884536743\n",
            "2.2838492393493652\n",
            "2.2828004360198975\n",
            "2.2817740440368652\n",
            "2.2807700634002686\n",
            "2.27978777885437\n",
            "2.278825521469116\n",
            "2.277883291244507\n",
            "2.276961088180542\n",
            "2.2760579586029053\n",
            "2.2751731872558594\n",
            "2.274306058883667\n",
            "2.273456573486328\n",
            "2.2726240158081055\n",
            "2.2718076705932617\n",
            "2.271007776260376\n",
            "2.270223379135132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xs[:10]"
      ],
      "metadata": {
        "id": "crvU517kIuum",
        "outputId": "15ea39ab-55c2-487c-8c3c-98ca01fc4c21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[12, 21],\n",
              "        [21, 20],\n",
              "        [20, 20],\n",
              "        [20,  9],\n",
              "        [12, 18],\n",
              "        [18,  3],\n",
              "        [ 3, 25],\n",
              "        [25,  1],\n",
              "        [ 1, 25],\n",
              "        [25,  9]])"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(xs):\n",
        "  xenc = functional.one_hot(xs, num_classes=vocab_len).float().flatten(start_dim=1)\n",
        "  logits = xenc @ ws\n",
        "  counts = logits.exp()\n",
        "  probs = counts / counts.sum(1, keepdims=True)\n",
        "  outchar = itos[torch.multinomial(probs, num_samples=1).item()]\n",
        "  return outchar\n",
        "\n",
        "def prompt(ins):\n",
        "  out = ins\n",
        "  for char in range(500):\n",
        "    last_two = ins[-2:]\n",
        "    xs = torch.tensor([[stoi[last_two[0]], stoi[last_two[1]]]])\n",
        "    outs = forward(xs)\n",
        "    out += outs\n",
        "  return out\n",
        "\n",
        "prompt(\"Rom\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "koeHicLTt4Os",
        "outputId": "656cee30-726e-4fa8-def5-affb36e5b3c9"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Rom.eistiiio.eagbpeai.eieillraiaaaeueyiaiesdaiae.aoiiaiiiaauaaaadaaa..tycyiii.aeeayoaifsa.aiyfpeaa.rai..aaf.aayeuaeiimlu.hyyeiiias.eibiaeaa.aeaa...aaaieeiaaaa.waaaaa.uaiyaaary.aay.i.aa..iaaiaahadpai..aiaafaariiuaaieeylyiwi.ap.ia.aa..i.ieuaaazeiiuea.aaieaaaiieiaef.yayea.a.iypay.asii..baiaiiinsa.i..rieaiiuyai.ayaaa.i.eibioyyaiaaiafiiaaaa.a.aey.iai...idaiafaaaugsiaayamue.ad.aui.ewi.aaaaenae.aieeiaaiaeafey.aaaibia.ia.aoiabeia.bneeeiiia.ai.iaiaieies.iefseiiaieaaauayeee.ea..y.faiah..axeia.iai.eaaaiaaeeaa'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make test set\n",
        "xs, ys = [], []\n",
        "for data in test_set:\n",
        "  for ch1, ch2, ch3 in zip(data, data[1:], data[2:]):\n",
        "    xs.append([stoi[ch1], stoi[ch2]])\n",
        "    ys.append(stoi[ch3])\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n",
        "num = xs.nelement()\n",
        "num"
      ],
      "metadata": {
        "id": "E1aCdrq5gMg0",
        "outputId": "d977d4fc-0ef9-4ccb-8273-1bce5dda28ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39052"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xenc = functional.one_hot(xs, num_classes=vocab_len).float().flatten(start_dim=1)\n",
        "logits = xenc @ ws\n",
        "counts = logits.exp()\n",
        "probs = counts / counts.sum(1, keepdim=True)\n",
        "loss = -probs[torch.arange(int(num / 2)), ys].log().mean() + (ws.mean() * 0.01)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "id": "c2U7N2msgXHI",
        "outputId": "b0a3f7d5-a106-4cd6-9f76-9ef85b23481c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4957985877990723\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make dev set\n",
        "xs, ys = [], []\n",
        "for data in dev_set:\n",
        "  for ch1, ch2, ch3 in zip(data, data[1:], data[2:]):\n",
        "    xs.append([stoi[ch1], stoi[ch2]])\n",
        "    ys.append(stoi[ch3])\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n",
        "num = xs.nelement()\n",
        "num"
      ],
      "metadata": {
        "id": "JDMlg63jgiCx",
        "outputId": "6e1a5d7b-43c5-486b-876e-49fe74b4704c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38860"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xenc = functional.one_hot(xs, num_classes=vocab_len).float().flatten(start_dim=1)\n",
        "logits = xenc @ ws\n",
        "counts = logits.exp()\n",
        "probs = counts / counts.sum(1, keepdim=True)\n",
        "loss = -probs[torch.arange(int(num / 2)), ys].log().mean() + (ws.mean() * 0.01)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "id": "qgB7lKsCgjSe",
        "outputId": "dd58abe2-f21b-44d5-c2b4-08c0c1ad1d23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.498171806335449\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks like it might be overfitting? The dev set results seem fine, but the test set loss it much higher than it should be."
      ],
      "metadata": {
        "id": "a87DpLMBgrDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make dev set\n",
        "dxs, dys = [], []\n",
        "for data in dev_set:\n",
        "  for ch1, ch2, ch3 in zip(data, data[1:], data[2:]):\n",
        "    dxs.append([stoi[ch1], stoi[ch2]])\n",
        "    dys.append(stoi[ch3])\n",
        "\n",
        "dxs = torch.tensor(xs)\n",
        "dys = torch.tensor(ys)\n",
        "dnum = xs.nelement()\n",
        "dnum"
      ],
      "metadata": {
        "id": "WoEddjEPiRJX",
        "outputId": "5baa7de2-e305-49d1-92a5-091d46675680",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-169-af72f93a7454>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  dxs = torch.tensor(xs)\n",
            "<ipython-input-169-af72f93a7454>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  dys = torch.tensor(ys)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38860"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ws = torch.randn((vocab_len*2, vocab_len))\n",
        "ws.requires_grad = True\n",
        "ws.shape"
      ],
      "metadata": {
        "id": "BSZuKtUTsQlS",
        "outputId": "a069f756-b024-4dbc-d26d-cd425131f2d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([54, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "lr = 20\n",
        "regularization = 0.01"
      ],
      "metadata": {
        "id": "CUeGNQeHhCso"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_loss = 2.1\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    dxenc = functional.one_hot(dxs, num_classes=vocab_len).float().flatten(start_dim=1)\n",
        "    dlogits = dxenc @ ws\n",
        "    dcounts = dlogits.exp()\n",
        "    dprobs = dcounts / dcounts.sum(1, keepdim=True)\n",
        "    dloss = -dprobs[torch.arange(int(num / 2)), dys].log().mean() + (ws.mean() * regularization)\n",
        "    dloss.detach()\n",
        "\n",
        "    xenc = functional.one_hot(xs, num_classes=vocab_len).float().flatten(start_dim=1)\n",
        "    logits = xenc @ ws\n",
        "    counts = logits.exp()\n",
        "    probs = counts / counts.sum(1, keepdim=True)\n",
        "    loss = -probs[torch.arange(int(num / 2)), ys].log().mean() + (ws.mean() * regularization * (abs(last_loss - dloss)))\n",
        "\n",
        "    print(loss.item())\n",
        "    ws.grad = None\n",
        "    loss.backward()\n",
        "    ws.data += ws.grad * -lr\n",
        "\n",
        "    last_loss = loss.item()"
      ],
      "metadata": {
        "id": "RO0WqQUBhGH-",
        "outputId": "719ef348-c77e-4b4b-e507-3c8c648c9309",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.185744285583496\n",
            "3.8254897594451904\n",
            "3.585930585861206\n",
            "3.418062925338745\n",
            "3.292776107788086\n",
            "3.192509174346924\n",
            "3.108778476715088\n",
            "3.0371713638305664\n",
            "2.975004196166992\n",
            "2.9204859733581543\n",
            "2.872347354888916\n",
            "2.8296351432800293\n",
            "2.791598320007324\n",
            "2.7576215267181396\n",
            "2.7271902561187744\n",
            "2.699868679046631\n",
            "2.6752824783325195\n",
            "2.6531100273132324\n",
            "2.633068561553955\n",
            "2.6149086952209473\n",
            "2.598407745361328\n",
            "2.583366870880127\n",
            "2.5696113109588623\n",
            "2.5569872856140137\n",
            "2.5453617572784424\n",
            "2.534620761871338\n",
            "2.5246663093566895\n",
            "2.515415668487549\n",
            "2.506795883178711\n",
            "2.4987456798553467\n",
            "2.491211175918579\n",
            "2.484145164489746\n",
            "2.477506160736084\n",
            "2.471256971359253\n",
            "2.465364694595337\n",
            "2.4597995281219482\n",
            "2.454535961151123\n",
            "2.4495487213134766\n",
            "2.4448165893554688\n",
            "2.4403204917907715\n",
            "2.436042308807373\n",
            "2.4319663047790527\n",
            "2.4280776977539062\n",
            "2.424363613128662\n",
            "2.4208126068115234\n",
            "2.417412757873535\n",
            "2.4141552448272705\n",
            "2.4110300540924072\n",
            "2.408029794692993\n",
            "2.405146598815918\n",
            "2.402374029159546\n",
            "2.399704933166504\n",
            "2.397134304046631\n",
            "2.3946564197540283\n",
            "2.392266035079956\n",
            "2.3899593353271484\n",
            "2.3877310752868652\n",
            "2.385577917098999\n",
            "2.383495807647705\n",
            "2.381481647491455\n",
            "2.3795320987701416\n",
            "2.377643585205078\n",
            "2.375814437866211\n",
            "2.3740408420562744\n",
            "2.3723206520080566\n",
            "2.3706517219543457\n",
            "2.3690309524536133\n",
            "2.367457151412964\n",
            "2.3659279346466064\n",
            "2.3644418716430664\n",
            "2.3629965782165527\n",
            "2.36159086227417\n",
            "2.360222339630127\n",
            "2.3588905334472656\n",
            "2.357593059539795\n",
            "2.3563294410705566\n",
            "2.355097532272339\n",
            "2.3538966178894043\n",
            "2.3527252674102783\n",
            "2.3515827655792236\n",
            "2.3504676818847656\n",
            "2.349379062652588\n",
            "2.348315954208374\n",
            "2.3472774028778076\n",
            "2.3462629318237305\n",
            "2.345271348953247\n",
            "2.34430193901062\n",
            "2.3433539867401123\n",
            "2.3424265384674072\n",
            "2.3415191173553467\n",
            "2.3406310081481934\n",
            "2.339761734008789\n",
            "2.3389105796813965\n",
            "2.3380768299102783\n",
            "2.3372602462768555\n",
            "2.3364598751068115\n",
            "2.3356757164001465\n",
            "2.334907054901123\n",
            "2.334152936935425\n",
            "2.333414077758789\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt(\".e\")"
      ],
      "metadata": {
        "id": "gk1RgGqtr9Gn",
        "outputId": "46cca8e0-83f2-48c9-92ee-0f12e38c04f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'.elrelzrlnlrlarraraurrlmzaulnrrrrrlvlhrnrbslnzrardylrltrlnalncelzllrovromermuyrveumairlblrrsllnrrrrlqlvllmlezrreurlalllrndmlyrvlllbrdlyratxrmrxsylrlrrzlnlilrimorcrrvmrsmydrllrlzxlmlrriialxrldlrclrzoisaalln.isnlrlrdrrasrltrraoeyelleelrynrrrrlleldarniliedlnllylelrryrlyrtmldlllaslyleiryrlnldsrbrrrl.dlnxyiyylrlhllmramlheedlhnrrlyyislalrrlgdrlalvalueorrulilllrralrrrnlxlrlllnrrraallrosilrrnrlreriarzxelyrvtdrlbllramalrnlrlirmlllrznsesyttrnzrlhlellmcvlarrskrrrreullsdlrlhrmdrvllmlsulrsalazvlrvmatraoalrhayr'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Idk, maybe? I've definitely screwed something up here but I have no idea what"
      ],
      "metadata": {
        "id": "ZIRWfgXmsdyV"
      }
    }
  ]
}